[0m18:32:42.327129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9AC1F6B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9A51D5B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9A51FEC0>]}


============================== 18:32:42.327129 | 547c1211-7b48-46e6-881d-ee86537b188e ==============================
[0m18:32:42.327129 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:32:42.327129 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\leleb\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt debug', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:32:42.383317 [info ] [MainThread]: dbt version: 1.8.7
[0m18:32:42.383317 [info ] [MainThread]: python version: 3.12.6
[0m18:32:42.395826 [info ] [MainThread]: python path: D:\Python\python.exe
[0m18:32:42.395826 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m18:32:42.578591 [info ] [MainThread]: Using profiles dir at C:\Users\leleb\.dbt
[0m18:32:42.578591 [info ] [MainThread]: Using profiles.yml file at C:\Users\leleb\.dbt\profiles.yml
[0m18:32:42.578591 [info ] [MainThread]: Using dbt_project.yml file at D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\dbt_project.yml
[0m18:32:42.617315 [info ] [MainThread]: adapter type: duckdb
[0m18:32:42.617315 [info ] [MainThread]: adapter version: 1.9.0
[0m18:32:42.729267 [info ] [MainThread]: Configuration:
[0m18:32:42.730268 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:32:42.731272 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:32:42.732267 [info ] [MainThread]: Required dependencies:
[0m18:32:42.733148 [debug] [MainThread]: Executing "git --help"
[0m18:32:42.825572 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:32:42.826576 [debug] [MainThread]: STDERR: "b''"
[0m18:32:42.826576 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:32:42.827817 [info ] [MainThread]: Connection:
[0m18:32:42.828844 [info ] [MainThread]:   database: dev
[0m18:32:42.829831 [info ] [MainThread]:   schema: main
[0m18:32:42.830830 [info ] [MainThread]:   path: dev.duckdb
[0m18:32:42.830830 [info ] [MainThread]:   config_options: None
[0m18:32:42.831832 [info ] [MainThread]:   extensions: None
[0m18:32:42.832909 [info ] [MainThread]:   settings: {}
[0m18:32:42.832909 [info ] [MainThread]:   external_root: .
[0m18:32:42.832909 [info ] [MainThread]:   use_credential_provider: None
[0m18:32:42.832909 [info ] [MainThread]:   attach: None
[0m18:32:42.832909 [info ] [MainThread]:   filesystems: None
[0m18:32:42.832909 [info ] [MainThread]:   remote: None
[0m18:32:42.832909 [info ] [MainThread]:   plugins: None
[0m18:32:42.832909 [info ] [MainThread]:   disable_transactions: False
[0m18:32:42.832909 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m18:32:42.832909 [debug] [MainThread]: Acquiring new duckdb connection 'debug'
[0m18:32:43.232152 [debug] [MainThread]: Using duckdb connection "debug"
[0m18:32:43.232152 [debug] [MainThread]: On debug: select 1 as id
[0m18:32:43.232152 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:32:43.551381 [debug] [MainThread]: SQL status: OK in 0.327 seconds
[0m18:32:43.551381 [debug] [MainThread]: On debug: Close
[0m18:32:43.568082 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:32:43.568082 [info ] [MainThread]: [32mAll checks passed![0m
[0m18:32:43.568082 [debug] [MainThread]: Command `dbt debug` succeeded at 18:32:43.568082 after 1.45 seconds
[0m18:32:43.568082 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m18:32:43.568082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9AEC8440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9C3D3E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE9C3D01D0>]}
[0m18:32:43.568082 [debug] [MainThread]: Flushing usage events
[0m18:35:04.959316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A767C5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A25C9BB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A56588F0>]}


============================== 18:35:04.959316 | 941f73af-42f1-43ed-a2d8-91139364dc8f ==============================
[0m18:35:04.959316 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:35:04.959316 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:35:05.543493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '941f73af-42f1-43ed-a2d8-91139364dc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A60C4BF0>]}
[0m18:35:05.614023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '941f73af-42f1-43ed-a2d8-91139364dc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A7B24470>]}
[0m18:35:05.614023 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m18:35:05.629650 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m18:35:05.629650 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m18:35:05.629650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '941f73af-42f1-43ed-a2d8-91139364dc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A8735160>]}
[0m18:35:07.233988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '941f73af-42f1-43ed-a2d8-91139364dc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A9F46240>]}
[0m18:35:07.449076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '941f73af-42f1-43ed-a2d8-91139364dc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218AA0C7C20>]}
[0m18:35:07.449076 [info ] [MainThread]: Found 2 models, 4 data tests, 421 macros
[0m18:35:07.449076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '941f73af-42f1-43ed-a2d8-91139364dc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A9E02480>]}
[0m18:35:07.449076 [info ] [MainThread]: 
[0m18:35:07.449076 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m18:35:07.464705 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_banco_ada'
[0m18:35:07.609936 [debug] [ThreadPool]: Using duckdb connection "list_banco_ada"
[0m18:35:07.609936 [debug] [ThreadPool]: On list_banco_ada: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_banco_ada"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"banco_ada"'
    
  
  
[0m18:35:07.618052 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:35:07.762283 [debug] [ThreadPool]: SQL status: OK in 0.147 seconds
[0m18:35:07.762283 [debug] [ThreadPool]: On list_banco_ada: Close
[0m18:35:07.770354 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_banco_ada, now create_banco_ada_main)
[0m18:35:07.770354 [debug] [ThreadPool]: Creating schema "database: "banco_ada"
schema: "main"
"
[0m18:35:07.780463 [debug] [ThreadPool]: Using duckdb connection "create_banco_ada_main"
[0m18:35:07.780463 [debug] [ThreadPool]: On create_banco_ada_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_banco_ada_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='banco_ada'
        and type='sqlite'
    
  
[0m18:35:07.780463 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:35:07.792603 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m18:35:07.792603 [debug] [ThreadPool]: Using duckdb connection "create_banco_ada_main"
[0m18:35:07.792603 [debug] [ThreadPool]: On create_banco_ada_main: BEGIN
[0m18:35:07.792603 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m18:35:07.792603 [debug] [ThreadPool]: Using duckdb connection "create_banco_ada_main"
[0m18:35:07.792603 [debug] [ThreadPool]: On create_banco_ada_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_banco_ada_main"} */

    
    
        create schema if not exists "banco_ada"."main"
    
[0m18:35:07.800743 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m18:35:07.800743 [debug] [ThreadPool]: On create_banco_ada_main: COMMIT
[0m18:35:07.800743 [debug] [ThreadPool]: Using duckdb connection "create_banco_ada_main"
[0m18:35:07.800743 [debug] [ThreadPool]: On create_banco_ada_main: COMMIT
[0m18:35:07.800743 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m18:35:07.800743 [debug] [ThreadPool]: On create_banco_ada_main: Close
[0m18:35:07.810756 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_banco_ada_main'
[0m18:35:07.810756 [debug] [ThreadPool]: Using duckdb connection "list_banco_ada_main"
[0m18:35:07.810756 [debug] [ThreadPool]: On list_banco_ada_main: BEGIN
[0m18:35:07.810756 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:35:07.829544 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m18:35:07.829544 [debug] [ThreadPool]: Using duckdb connection "list_banco_ada_main"
[0m18:35:07.830543 [debug] [ThreadPool]: On list_banco_ada_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_banco_ada_main"} */
select
      'banco_ada' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'banco_ada'
  
[0m18:35:08.026354 [debug] [ThreadPool]: SQL status: OK in 0.204 seconds
[0m18:35:08.026354 [debug] [ThreadPool]: On list_banco_ada_main: ROLLBACK
[0m18:35:08.041979 [debug] [ThreadPool]: Failed to rollback 'list_banco_ada_main'
[0m18:35:08.041979 [debug] [ThreadPool]: On list_banco_ada_main: Close
[0m18:35:08.041979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '941f73af-42f1-43ed-a2d8-91139364dc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A6138710>]}
[0m18:35:08.041979 [debug] [MainThread]: Using duckdb connection "master"
[0m18:35:08.041979 [debug] [MainThread]: On master: BEGIN
[0m18:35:08.041979 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:35:08.058565 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m18:35:08.060842 [debug] [MainThread]: On master: COMMIT
[0m18:35:08.060842 [debug] [MainThread]: Using duckdb connection "master"
[0m18:35:08.061845 [debug] [MainThread]: On master: COMMIT
[0m18:35:08.061845 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m18:35:08.062844 [debug] [MainThread]: On master: Close
[0m18:35:08.065840 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:35:08.065840 [info ] [MainThread]: 
[0m18:35:08.073883 [debug] [Thread-1 (]: Began running node model.data_quality.my_first_dbt_model
[0m18:35:08.075431 [info ] [Thread-1 (]: 1 of 2 START sql table model main.my_first_dbt_model ........................... [RUN]
[0m18:35:08.076430 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.data_quality.my_first_dbt_model'
[0m18:35:08.076430 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_first_dbt_model
[0m18:35:08.079132 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_first_dbt_model"
[0m18:35:08.094873 [debug] [Thread-1 (]: Began executing node model.data_quality.my_first_dbt_model
[0m18:35:08.161308 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_first_dbt_model"
[0m18:35:08.164304 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m18:35:08.165306 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: BEGIN
[0m18:35:08.165306 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:35:08.176307 [debug] [Thread-1 (]: SQL status: OK in 0.010 seconds
[0m18:35:08.176307 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m18:35:08.177798 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */

  
    
    

    create  table
      "banco_ada"."main"."my_first_dbt_model__dbt_tmp"
  
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
  
[0m18:35:08.194850 [debug] [Thread-1 (]: SQL status: OK in 0.031 seconds
[0m18:35:08.210988 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m18:35:08.210988 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
alter table "banco_ada"."main"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:35:08.210988 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m18:35:08.242253 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m18:35:08.242253 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m18:35:08.242253 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m18:35:08.273502 [debug] [Thread-1 (]: SQL status: OK in 0.028 seconds
[0m18:35:08.273502 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m18:35:08.273502 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
drop table if exists "banco_ada"."main"."my_first_dbt_model__dbt_backup" cascade
[0m18:35:08.273502 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m18:35:08.273502 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: Close
[0m18:35:08.373791 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '941f73af-42f1-43ed-a2d8-91139364dc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A609FCE0>]}
[0m18:35:08.389421 [info ] [Thread-1 (]: 1 of 2 OK created sql table model main.my_first_dbt_model ...................... [[32mOK[0m in 0.30s]
[0m18:35:08.389421 [debug] [Thread-1 (]: Finished running node model.data_quality.my_first_dbt_model
[0m18:35:08.389421 [debug] [Thread-1 (]: Began running node model.data_quality.my_second_dbt_model
[0m18:35:08.389421 [info ] [Thread-1 (]: 2 of 2 START sql view model main.my_second_dbt_model ........................... [RUN]
[0m18:35:08.389421 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_quality.my_first_dbt_model, now model.data_quality.my_second_dbt_model)
[0m18:35:08.389421 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_second_dbt_model
[0m18:35:08.389421 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_second_dbt_model"
[0m18:35:08.389421 [debug] [Thread-1 (]: Began executing node model.data_quality.my_second_dbt_model
[0m18:35:08.484904 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_second_dbt_model"
[0m18:35:08.494266 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m18:35:08.494266 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: BEGIN
[0m18:35:08.495269 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:35:08.530827 [debug] [Thread-1 (]: SQL status: OK in 0.036 seconds
[0m18:35:08.530827 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m18:35:08.530827 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */

  
  create view "banco_ada"."main"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "banco_ada"."main"."my_first_dbt_model"
where id = 1
  );

[0m18:35:08.530827 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m18:35:08.530827 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m18:35:08.530827 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
alter view "banco_ada"."main"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:35:08.547339 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m18:35:08.547339 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m18:35:08.547339 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m18:35:08.547339 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m18:35:08.597262 [debug] [Thread-1 (]: SQL status: OK in 0.043 seconds
[0m18:35:08.600264 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m18:35:08.601264 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
drop view if exists "banco_ada"."main"."my_second_dbt_model__dbt_backup" cascade
[0m18:35:08.602263 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m18:35:08.604264 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: Close
[0m18:35:08.658902 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '941f73af-42f1-43ed-a2d8-91139364dc8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218AA54A810>]}
[0m18:35:08.658902 [info ] [Thread-1 (]: 2 of 2 OK created sql view model main.my_second_dbt_model ...................... [[32mOK[0m in 0.27s]
[0m18:35:08.674534 [debug] [Thread-1 (]: Finished running node model.data_quality.my_second_dbt_model
[0m18:35:08.674534 [debug] [MainThread]: Using duckdb connection "master"
[0m18:35:08.674534 [debug] [MainThread]: On master: BEGIN
[0m18:35:08.674534 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:35:08.690155 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m18:35:08.690155 [debug] [MainThread]: On master: COMMIT
[0m18:35:08.691423 [debug] [MainThread]: Using duckdb connection "master"
[0m18:35:08.691423 [debug] [MainThread]: On master: COMMIT
[0m18:35:08.692938 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m18:35:08.693941 [debug] [MainThread]: On master: Close
[0m18:35:08.696847 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:35:08.696847 [debug] [MainThread]: Connection 'create_banco_ada_main' was properly closed.
[0m18:35:08.696847 [debug] [MainThread]: Connection 'list_banco_ada_main' was properly closed.
[0m18:35:08.696847 [debug] [MainThread]: Connection 'model.data_quality.my_second_dbt_model' was properly closed.
[0m18:35:08.696847 [info ] [MainThread]: 
[0m18:35:08.696847 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.25 seconds (1.25s).
[0m18:35:08.696847 [debug] [MainThread]: Command end result
[0m18:35:08.751243 [info ] [MainThread]: 
[0m18:35:08.751243 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:35:08.751243 [info ] [MainThread]: 
[0m18:35:08.751243 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:35:08.757859 [debug] [MainThread]: Command `dbt run` succeeded at 18:35:08.757859 after 4.05 seconds
[0m18:35:08.758399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A25C9BB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A767F650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218A767C5F0>]}
[0m18:35:08.759488 [debug] [MainThread]: Flushing usage events
[0m18:35:28.703761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EAC234260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EAFD70530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EAF4F25A0>]}


============================== 18:35:28.703761 | 3cf35768-469a-4001-8b81-c489afd21851 ==============================
[0m18:35:28.703761 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:35:28.703761 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'debug': 'False', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:35:29.057157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3cf35768-469a-4001-8b81-c489afd21851', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EB0744E60>]}
[0m18:35:29.128338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3cf35768-469a-4001-8b81-c489afd21851', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EB07447A0>]}
[0m18:35:29.130367 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m18:35:29.148443 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m18:35:29.306208 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m18:35:29.306208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3cf35768-469a-4001-8b81-c489afd21851', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EAFDA71A0>]}
[0m18:35:30.839759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3cf35768-469a-4001-8b81-c489afd21851', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EB1CDF6B0>]}
[0m18:35:30.956403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3cf35768-469a-4001-8b81-c489afd21851', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EB20CC200>]}
[0m18:35:30.957403 [info ] [MainThread]: Found 2 models, 4 data tests, 421 macros
[0m18:35:30.957965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3cf35768-469a-4001-8b81-c489afd21851', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EAE1DEC90>]}
[0m18:35:30.960842 [info ] [MainThread]: 
[0m18:35:30.961420 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m18:35:30.967900 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_data_quality'
[0m18:35:31.103052 [debug] [ThreadPool]: Using duckdb connection "list_data_quality"
[0m18:35:31.103052 [debug] [ThreadPool]: On list_data_quality: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"data_quality"'
    
  
  
[0m18:35:31.103052 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:35:31.155188 [debug] [ThreadPool]: SQL status: OK in 0.038 seconds
[0m18:35:31.157221 [debug] [ThreadPool]: On list_data_quality: Close
[0m18:35:31.157221 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_quality, now create_data_quality_main)
[0m18:35:31.157221 [debug] [ThreadPool]: Creating schema "database: "data_quality"
schema: "main"
"
[0m18:35:31.171652 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m18:35:31.171652 [debug] [ThreadPool]: On create_data_quality_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_data_quality_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='data_quality'
        and type='sqlite'
    
  
[0m18:35:31.171652 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:35:31.171652 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m18:35:31.184585 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m18:35:31.185582 [debug] [ThreadPool]: On create_data_quality_main: BEGIN
[0m18:35:31.185582 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m18:35:31.186479 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m18:35:31.186479 [debug] [ThreadPool]: On create_data_quality_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_data_quality_main"} */

    
    
        create schema if not exists "data_quality"."main"
    
[0m18:35:31.186479 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m18:35:31.186479 [debug] [ThreadPool]: On create_data_quality_main: COMMIT
[0m18:35:31.186479 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m18:35:31.186479 [debug] [ThreadPool]: On create_data_quality_main: COMMIT
[0m18:35:31.186479 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m18:35:31.186479 [debug] [ThreadPool]: On create_data_quality_main: Close
[0m18:35:31.186479 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_data_quality_main'
[0m18:35:31.202999 [debug] [ThreadPool]: Using duckdb connection "list_data_quality_main"
[0m18:35:31.202999 [debug] [ThreadPool]: On list_data_quality_main: BEGIN
[0m18:35:31.202999 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:35:31.202999 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m18:35:31.202999 [debug] [ThreadPool]: Using duckdb connection "list_data_quality_main"
[0m18:35:31.202999 [debug] [ThreadPool]: On list_data_quality_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality_main"} */
select
      'data_quality' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'data_quality'
  
[0m18:35:31.252789 [debug] [ThreadPool]: SQL status: OK in 0.046 seconds
[0m18:35:31.252789 [debug] [ThreadPool]: On list_data_quality_main: ROLLBACK
[0m18:35:31.252789 [debug] [ThreadPool]: Failed to rollback 'list_data_quality_main'
[0m18:35:31.252789 [debug] [ThreadPool]: On list_data_quality_main: Close
[0m18:35:31.269567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3cf35768-469a-4001-8b81-c489afd21851', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EB0789910>]}
[0m18:35:31.269567 [debug] [MainThread]: Using duckdb connection "master"
[0m18:35:31.271576 [debug] [MainThread]: On master: BEGIN
[0m18:35:31.271576 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:35:31.271576 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m18:35:31.271576 [debug] [MainThread]: On master: COMMIT
[0m18:35:31.271576 [debug] [MainThread]: Using duckdb connection "master"
[0m18:35:31.271576 [debug] [MainThread]: On master: COMMIT
[0m18:35:31.271576 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m18:35:31.284634 [debug] [MainThread]: On master: Close
[0m18:35:31.286316 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:35:31.286316 [info ] [MainThread]: 
[0m18:35:31.286316 [debug] [Thread-1 (]: Began running node model.data_quality.my_first_dbt_model
[0m18:35:31.286316 [info ] [Thread-1 (]: 1 of 2 START sql table model main.my_first_dbt_model ........................... [RUN]
[0m18:35:31.286316 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.data_quality.my_first_dbt_model'
[0m18:35:31.286316 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_first_dbt_model
[0m18:35:31.305310 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_first_dbt_model"
[0m18:35:31.307311 [debug] [Thread-1 (]: Began executing node model.data_quality.my_first_dbt_model
[0m18:35:31.420045 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_first_dbt_model"
[0m18:35:31.420045 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m18:35:31.420045 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: BEGIN
[0m18:35:31.420045 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m18:35:31.438702 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m18:35:31.439706 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m18:35:31.440707 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */

  
    
    

    create  table
      "data_quality"."main"."my_first_dbt_model__dbt_tmp"
  
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
  
[0m18:35:31.442705 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m18:35:31.452624 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m18:35:31.453622 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
alter table "data_quality"."main"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m18:35:31.454622 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m18:35:31.489055 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m18:35:31.490078 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m18:35:31.490622 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m18:35:31.509965 [debug] [Thread-1 (]: SQL status: OK in 0.024 seconds
[0m18:35:31.525566 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m18:35:31.526241 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
drop table if exists "data_quality"."main"."my_first_dbt_model__dbt_backup" cascade
[0m18:35:31.527465 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m18:35:31.530460 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: Close
[0m18:35:31.586258 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cf35768-469a-4001-8b81-c489afd21851', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EB1F71BB0>]}
[0m18:35:31.586258 [info ] [Thread-1 (]: 1 of 2 OK created sql table model main.my_first_dbt_model ...................... [[32mOK[0m in 0.30s]
[0m18:35:31.586258 [debug] [Thread-1 (]: Finished running node model.data_quality.my_first_dbt_model
[0m18:35:31.586258 [debug] [Thread-1 (]: Began running node model.data_quality.my_second_dbt_model
[0m18:35:31.586258 [info ] [Thread-1 (]: 2 of 2 START sql view model main.my_second_dbt_model ........................... [RUN]
[0m18:35:31.586258 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_quality.my_first_dbt_model, now model.data_quality.my_second_dbt_model)
[0m18:35:31.586258 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_second_dbt_model
[0m18:35:31.586258 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_second_dbt_model"
[0m18:35:31.586258 [debug] [Thread-1 (]: Began executing node model.data_quality.my_second_dbt_model
[0m18:35:31.627012 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_second_dbt_model"
[0m18:35:31.627012 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m18:35:31.627012 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: BEGIN
[0m18:35:31.627012 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:35:31.641417 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m18:35:31.641417 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m18:35:31.641417 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */

  
  create view "data_quality"."main"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "data_quality"."main"."my_first_dbt_model"
where id = 1
  );

[0m18:35:31.641417 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m18:35:31.641417 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m18:35:31.641417 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
alter view "data_quality"."main"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m18:35:31.651389 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m18:35:31.653944 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m18:35:31.653944 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m18:35:31.653944 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m18:35:31.672051 [debug] [Thread-1 (]: SQL status: OK in 0.024 seconds
[0m18:35:31.672051 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m18:35:31.672051 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
drop view if exists "data_quality"."main"."my_second_dbt_model__dbt_backup" cascade
[0m18:35:31.672051 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m18:35:31.686354 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: Close
[0m18:35:31.753028 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cf35768-469a-4001-8b81-c489afd21851', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EB1FC5310>]}
[0m18:35:31.753028 [info ] [Thread-1 (]: 2 of 2 OK created sql view model main.my_second_dbt_model ...................... [[32mOK[0m in 0.17s]
[0m18:35:31.753028 [debug] [Thread-1 (]: Finished running node model.data_quality.my_second_dbt_model
[0m18:35:31.753028 [debug] [MainThread]: Using duckdb connection "master"
[0m18:35:31.753028 [debug] [MainThread]: On master: BEGIN
[0m18:35:31.753028 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:35:31.772310 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m18:35:31.772310 [debug] [MainThread]: On master: COMMIT
[0m18:35:31.772310 [debug] [MainThread]: Using duckdb connection "master"
[0m18:35:31.772310 [debug] [MainThread]: On master: COMMIT
[0m18:35:31.772310 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m18:35:31.772310 [debug] [MainThread]: On master: Close
[0m18:35:31.772310 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:35:31.772310 [debug] [MainThread]: Connection 'create_data_quality_main' was properly closed.
[0m18:35:31.772310 [debug] [MainThread]: Connection 'list_data_quality_main' was properly closed.
[0m18:35:31.772310 [debug] [MainThread]: Connection 'model.data_quality.my_second_dbt_model' was properly closed.
[0m18:35:31.772310 [info ] [MainThread]: 
[0m18:35:31.772310 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.81 seconds (0.81s).
[0m18:35:31.772310 [debug] [MainThread]: Command end result
[0m18:35:31.820603 [info ] [MainThread]: 
[0m18:35:31.820603 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:35:31.820603 [info ] [MainThread]: 
[0m18:35:31.820603 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:35:31.820603 [debug] [MainThread]: Command `dbt run` succeeded at 18:35:31.820603 after 3.29 seconds
[0m18:35:31.820603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EB02E4E30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EB034F260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015EADB91F40>]}
[0m18:35:31.820603 [debug] [MainThread]: Flushing usage events
[0m18:41:54.594124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C30C521E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C30D38260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C335DF830>]}


============================== 18:41:54.609766 | c3cb8d21-536f-4c79-8a62-f7bc7b954d3c ==============================
[0m18:41:54.609766 [info ] [MainThread]: Running with dbt=1.8.7
[0m18:41:54.609766 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'version_check': 'True', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt seed', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:41:54.955491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c3cb8d21-536f-4c79-8a62-f7bc7b954d3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C2F48B320>]}
[0m18:41:55.026342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c3cb8d21-536f-4c79-8a62-f7bc7b954d3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C3274E270>]}
[0m18:41:55.033343 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m18:41:55.037425 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m18:41:55.232400 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 3 files added, 0 files changed.
[0m18:41:55.232400 [debug] [MainThread]: Partial parsing: added file: data_quality://seeds\reviews.csv
[0m18:41:55.232400 [debug] [MainThread]: Partial parsing: added file: data_quality://seeds\listings.csv
[0m18:41:55.232400 [debug] [MainThread]: Partial parsing: added file: data_quality://seeds\calendar.csv
[0m18:41:55.524342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c3cb8d21-536f-4c79-8a62-f7bc7b954d3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C335B18E0>]}
[0m18:41:55.693825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c3cb8d21-536f-4c79-8a62-f7bc7b954d3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C34FDA8A0>]}
[0m18:41:55.693825 [info ] [MainThread]: Found 2 models, 4 data tests, 3 seeds, 421 macros
[0m18:41:55.693825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c3cb8d21-536f-4c79-8a62-f7bc7b954d3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C3399B890>]}
[0m18:41:55.709444 [info ] [MainThread]: 
[0m18:41:55.709444 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m18:41:55.709444 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_data_quality'
[0m18:41:55.862853 [debug] [ThreadPool]: Using duckdb connection "list_data_quality"
[0m18:41:55.862853 [debug] [ThreadPool]: On list_data_quality: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"data_quality"'
    
  
  
[0m18:41:55.862853 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:41:55.862853 [debug] [ThreadPool]: SQL status: OK in 0.014 seconds
[0m18:41:55.878477 [debug] [ThreadPool]: On list_data_quality: Close
[0m18:41:55.878477 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_quality, now create_data_quality_main)
[0m18:41:55.878477 [debug] [ThreadPool]: Creating schema "database: "data_quality"
schema: "main"
"
[0m18:41:55.878477 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m18:41:55.878477 [debug] [ThreadPool]: On create_data_quality_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_data_quality_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='data_quality'
        and type='sqlite'
    
  
[0m18:41:55.878477 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:41:55.894103 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m18:41:55.894103 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m18:41:55.894103 [debug] [ThreadPool]: On create_data_quality_main: BEGIN
[0m18:41:55.894103 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m18:41:55.894103 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m18:41:55.894103 [debug] [ThreadPool]: On create_data_quality_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_data_quality_main"} */

    
    
        create schema if not exists "data_quality"."main"
    
[0m18:41:55.894103 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m18:41:55.909726 [debug] [ThreadPool]: On create_data_quality_main: COMMIT
[0m18:41:55.909726 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m18:41:55.909726 [debug] [ThreadPool]: On create_data_quality_main: COMMIT
[0m18:41:55.909726 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m18:41:55.909726 [debug] [ThreadPool]: On create_data_quality_main: Close
[0m18:41:55.909726 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_data_quality_main'
[0m18:41:55.909726 [debug] [ThreadPool]: Using duckdb connection "list_data_quality_main"
[0m18:41:55.909726 [debug] [ThreadPool]: On list_data_quality_main: BEGIN
[0m18:41:55.909726 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:41:55.925351 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m18:41:55.925351 [debug] [ThreadPool]: Using duckdb connection "list_data_quality_main"
[0m18:41:55.925351 [debug] [ThreadPool]: On list_data_quality_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality_main"} */
select
      'data_quality' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'data_quality'
  
[0m18:41:55.978758 [debug] [ThreadPool]: SQL status: OK in 0.048 seconds
[0m18:41:55.978758 [debug] [ThreadPool]: On list_data_quality_main: ROLLBACK
[0m18:41:55.978758 [debug] [ThreadPool]: Failed to rollback 'list_data_quality_main'
[0m18:41:55.978758 [debug] [ThreadPool]: On list_data_quality_main: Close
[0m18:41:55.978758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c3cb8d21-536f-4c79-8a62-f7bc7b954d3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C35088560>]}
[0m18:41:55.978758 [debug] [MainThread]: Using duckdb connection "master"
[0m18:41:55.994384 [debug] [MainThread]: On master: BEGIN
[0m18:41:55.994384 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:41:56.009723 [debug] [MainThread]: SQL status: OK in 0.014 seconds
[0m18:41:56.010326 [debug] [MainThread]: On master: COMMIT
[0m18:41:56.010872 [debug] [MainThread]: Using duckdb connection "master"
[0m18:41:56.011418 [debug] [MainThread]: On master: COMMIT
[0m18:41:56.011966 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m18:41:56.012515 [debug] [MainThread]: On master: Close
[0m18:41:56.015244 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:41:56.015798 [info ] [MainThread]: 
[0m18:41:56.020659 [debug] [Thread-1 (]: Began running node seed.data_quality.calendar
[0m18:41:56.021726 [info ] [Thread-1 (]: 1 of 3 START seed file main.calendar ........................................... [RUN]
[0m18:41:56.022790 [debug] [Thread-1 (]: Acquiring new duckdb connection 'seed.data_quality.calendar'
[0m18:41:56.023325 [debug] [Thread-1 (]: Began compiling node seed.data_quality.calendar
[0m18:41:56.023853 [debug] [Thread-1 (]: Began executing node seed.data_quality.calendar
[0m19:01:39.936595 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.calendar"
[0m19:01:39.967759 [debug] [Thread-1 (]: On seed.data_quality.calendar: BEGIN
[0m19:01:39.967759 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:01:41.438465 [debug] [Thread-1 (]: SQL status: OK in 1.470 seconds
[0m19:01:41.438465 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.calendar"
[0m19:01:41.442466 [debug] [Thread-1 (]: On seed.data_quality.calendar: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "seed.data_quality.calendar"} */

    create table "data_quality"."main"."calendar" ("listing_id" integer,"date" date,"available" text,"price" float8,"adjusted_price" integer,"minimum_nights" integer,"maximum_nights" integer)
  
[0m19:01:41.452627 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m19:01:41.768629 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.calendar"
[0m19:01:41.768629 [debug] [Thread-1 (]: On seed.data_quality.calendar: 
          COPY "data_quality"."main"."calendar" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\calendar.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m19:11:07.682274 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: 
          COPY "data_quality"."main"."calendar" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\calendar.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        
[0m19:11:07.684274 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m19:11:07.686277 [debug] [Thread-1 (]: On seed.data_quality.calendar: ROLLBACK
[0m19:11:08.071543 [debug] [Thread-1 (]: Failed to rollback 'seed.data_quality.calendar'
[0m19:11:08.073544 [debug] [Thread-1 (]: On seed.data_quality.calendar: Close
[0m19:11:08.142554 [debug] [Thread-1 (]: Runtime Error in seed calendar (seeds\calendar.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 297908,2024-06-27,f,$250.00,,2,1125
  Error when converting column "price". Could not convert string "$250.00" to 'DOUBLE'
  
  Column price is being converted as type DOUBLE
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\calendar.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 2 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 3 Set type: DOUBLE Sniffed type: VARCHAR
  Column at position: 4 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 5 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 6 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m19:11:08.178227 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3cb8d21-536f-4c79-8a62-f7bc7b954d3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C354D6E40>]}
[0m19:11:08.189203 [error] [Thread-1 (]: 1 of 3 ERROR loading seed file main.calendar ................................... [[31mERROR[0m in 1752.12s]
[0m19:11:08.195206 [debug] [Thread-1 (]: Finished running node seed.data_quality.calendar
[0m19:11:08.212206 [debug] [Thread-1 (]: Began running node seed.data_quality.listings
[0m19:11:08.219207 [info ] [Thread-1 (]: 2 of 3 START seed file main.listings ........................................... [RUN]
[0m19:11:08.221203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.data_quality.calendar, now seed.data_quality.listings)
[0m19:11:08.223202 [debug] [Thread-1 (]: Began compiling node seed.data_quality.listings
[0m19:11:08.224204 [debug] [Thread-1 (]: Began executing node seed.data_quality.listings
[0m19:11:34.148991 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.listings"
[0m19:11:34.149993 [debug] [Thread-1 (]: On seed.data_quality.listings: BEGIN
[0m19:11:34.150995 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:11:34.161991 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m19:11:34.162995 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.listings"
[0m19:11:34.163990 [debug] [Thread-1 (]: On seed.data_quality.listings: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "seed.data_quality.listings"} */

    create table "data_quality"."main"."listings" ("id" integer,"listing_url" text,"scrape_id" integer,"last_scraped" date,"source" text,"name" text,"description" text,"neighborhood_overview" text,"picture_url" text,"host_id" integer,"host_url" text,"host_name" text,"host_since" date,"host_location" text,"host_about" text,"host_response_time" text,"host_response_rate" text,"host_acceptance_rate" text,"host_is_superhost" text,"host_thumbnail_url" text,"host_picture_url" text,"host_neighbourhood" text,"host_listings_count" integer,"host_total_listings_count" integer,"host_verifications" text,"host_has_profile_pic" text,"host_identity_verified" text,"neighbourhood" text,"neighbourhood_cleansed" text,"neighbourhood_group_cleansed" integer,"latitude" float8,"longitude" float8,"property_type" text,"room_type" text,"accommodates" integer,"bathrooms" float8,"bathrooms_text" text,"bedrooms" integer,"beds" integer,"amenities" text,"price" integer,"minimum_nights" integer,"maximum_nights" integer,"minimum_minimum_nights" integer,"maximum_minimum_nights" integer,"minimum_maximum_nights" integer,"maximum_maximum_nights" integer,"minimum_nights_avg_ntm" float8,"maximum_nights_avg_ntm" float8,"calendar_updated" integer,"has_availability" text,"availability_30" integer,"availability_60" integer,"availability_90" integer,"availability_365" integer,"calendar_last_scraped" date,"number_of_reviews" integer,"number_of_reviews_ltm" integer,"number_of_reviews_l30d" integer,"first_review" date,"last_review" date,"review_scores_rating" float8,"review_scores_accuracy" float8,"review_scores_cleanliness" float8,"review_scores_checkin" float8,"review_scores_communication" float8,"review_scores_location" float8,"review_scores_value" float8,"license" integer,"instant_bookable" text,"calculated_host_listings_count" integer,"calculated_host_listings_count_entire_homes" integer,"calculated_host_listings_count_private_rooms" integer,"calculated_host_listings_count_shared_rooms" integer,"reviews_per_month" float8)
  
[0m19:11:34.165990 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m19:11:34.167989 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.listings"
[0m19:11:34.167989 [debug] [Thread-1 (]: On seed.data_quality.listings: 
          COPY "data_quality"."main"."listings" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\listings.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m19:11:34.496994 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: 
          COPY "data_quality"."main"."listings" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\listings.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        
[0m19:11:34.496994 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m19:11:34.497994 [debug] [Thread-1 (]: On seed.data_quality.listings: ROLLBACK
[0m19:11:34.503994 [debug] [Thread-1 (]: Failed to rollback 'seed.data_quality.listings'
[0m19:11:34.504994 [debug] [Thread-1 (]: On seed.data_quality.listings: Close
[0m19:11:34.513989 [debug] [Thread-1 (]: Runtime Error in seed listings (seeds\listings.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 17878,https://www.airbnb.com/rooms/17878,20240627045056,2024-06-28,city scrape,"Very Nice 2Br in Copacabana w. balcony, fast WiFi","Please note that elevated rates applies for New Years and Carnival. Price depends on length of stay and number of people. Generally I prefer a stay for 1 week or more and a maximum of 5 people (6 at the most). Contact me, and we will discuss. <br />- Bright and sunny<br />- Large balcony (25 square meters) <br />- High speed WiFi (up to 500MB)<br />- Smart TV (you can watch Netflix etc. if you have an account)<br />- 24h doorman<br />- 1 minute to walk to Copacabana Beach<br />- Silent ""split"" air conditioning<br />- Best spot in Rio","This is the one of the bests spots in Rio. Because of the large balcony and proximity to the beach, it has huge advantages in the current situation.",https://a0.muscache.com/pictures/65320518/30698f38_original.jpg,68997,https://www.airbnb.com/users/show/68997,Matthias,2010-01-08,"Rio de Janeiro, Brazil","I  am a  journalist/writer. Lived  in NYC for 15 years. I  am now based in Rio and published 3 volumes of travel stories on AMAZ0N: ""The World Is My Oyster"". If you have never been to Rio, check out the first story, and you'll get an idea. Apart from Rio, you'll find  29 other travel stories from all around the globe.",within an hour,100%,100%,t,https://a0.muscache.com/im/pictures/user/67b13cea-8c11-49c0-a08d-7f42c330676e.jpg?aki_policy=profile_small,https://a0.muscache.com/im/pictures/user/67b13cea-8c11-49c0-a08d-7f42c330676e.jpg?aki_policy=profile_x_medium,Copacabana,2,5,"['email', 'phone']",t,t,"Rio de Janeiro, Brazil",Copacabana,,-22.96599,-43.1794,Entire condo,Entire home/apt,5,1.0,1 bath,2,2,"[""Smoking allowed"", ""Essentials"", ""Air conditioning"", ""Hangers"", ""Building staff"", ""Kitchen"", ""Refrigerator"", ""Bathtub"", ""Dishes and silverware"", ""Hot water"", ""Microwave"", ""Elevator"", ""Luggage dropoff allowed"", ""Coffee maker"", ""Bed linens"", ""Private entrance"", ""Hair dryer"", ""Iron"", ""Self check-in"", ""Oven"", ""Stove"", ""Patio or balcony"", ""TV with standard cable"", ""Cooking basics"", ""Wifi"", ""Paid parking off premises""]",$310.00,5,28,5,5,28,28,5.0,28.0,,t,6,32,51,274,2024-06-28,319,23,1,2010-07-15,2024-06-08,4.71,4.77,4.64,4.84,4.91,4.77,4.67,,f,1,1,0,0,1.88
  Error when converting column "scrape_id". Could not convert string "20240627045056" to 'INTEGER'
  
  Column scrape_id is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\listings.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 2 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 9 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 18 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 22 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 23 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 25 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 26 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 29 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 34 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 37 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 38 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 40 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 41 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 42 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 43 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 44 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 45 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 46 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 49 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 50 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 51 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 52 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 53 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 54 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 56 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 57 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 58 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 68 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 69 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 70 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 71 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 72 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 73 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m19:11:34.526589 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3cb8d21-536f-4c79-8a62-f7bc7b954d3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C3539E600>]}
[0m19:11:34.528610 [error] [Thread-1 (]: 2 of 3 ERROR loading seed file main.listings ................................... [[31mERROR[0m in 26.31s]
[0m19:11:34.530611 [debug] [Thread-1 (]: Finished running node seed.data_quality.listings
[0m19:11:34.530611 [debug] [Thread-1 (]: Began running node seed.data_quality.reviews
[0m19:11:34.531610 [info ] [Thread-1 (]: 3 of 3 START seed file main.reviews ............................................ [RUN]
[0m19:11:34.533611 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.data_quality.listings, now seed.data_quality.reviews)
[0m19:11:34.534609 [debug] [Thread-1 (]: Began compiling node seed.data_quality.reviews
[0m19:11:34.535610 [debug] [Thread-1 (]: Began executing node seed.data_quality.reviews
[0m19:12:56.408899 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.reviews"
[0m19:12:56.409900 [debug] [Thread-1 (]: On seed.data_quality.reviews: BEGIN
[0m19:12:56.410900 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:12:56.421899 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m19:12:56.422900 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.reviews"
[0m19:12:56.422900 [debug] [Thread-1 (]: On seed.data_quality.reviews: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "seed.data_quality.reviews"} */

    create table "data_quality"."main"."reviews" ("listing_id" integer,"id" integer,"date" date,"reviewer_id" integer,"reviewer_name" text,"comments" text)
  
[0m19:12:56.424900 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m19:12:56.426900 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.reviews"
[0m19:12:56.427898 [debug] [Thread-1 (]: On seed.data_quality.reviews: 
          COPY "data_quality"."main"."reviews" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\reviews.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m19:12:56.536900 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: 
          COPY "data_quality"."main"."reviews" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\reviews.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        
[0m19:12:56.538899 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m19:12:56.540902 [debug] [Thread-1 (]: On seed.data_quality.reviews: ROLLBACK
[0m19:12:56.546899 [debug] [Thread-1 (]: Failed to rollback 'seed.data_quality.reviews'
[0m19:12:56.546899 [debug] [Thread-1 (]: On seed.data_quality.reviews: Close
[0m19:12:56.554899 [debug] [Thread-1 (]: Runtime Error in seed reviews (seeds\reviews.csv)
  Conversion Error: CSV Error on Line: 15
  Original Line: 220377,1122452741612760649,2024-03-28,74325704,Kayque,"Taciana me fez sentir-se na minha pr√≥pria casa. Que sorte eu tive de escolher este Airbnb no Rio de Janeiro! Al√©m da recep√ß√£o muito calorosa da anfitria, foi flex√≠vel com rela√ß√£o ao hor√°rio de chegada e sa√≠da. <br/>O apartamento √© lindo, super limpo e bem decorado, exatamente como mostra no an√∫ncio! Pr√≥ximo a tudo que precisei, bem servido de restaurantes, academias, supermercados, academias, frutaria, etc. O bairro √© bem tranquilo e acolhedor, com arredores bonito! <br/>Super recomendo, atendeu todas as expectativas! <br/>Custo x Benef√≠cio √≥timo. E depois de dias fora de casa, o apto dela nos remeteu um pouco do nosso lar, onde meu filho se sentiu bem relaxado e a vontade. Pessoal recomendo, pois √© um ambiente bem fam√≠lia.<br/>Priscila<br/>janeiro de"
  Error when converting column "id". Could not convert string "1122452741612760649" to 'INTEGER'
  
  Column id is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\reviews.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 1 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 3 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m19:12:56.555898 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3cb8d21-536f-4c79-8a62-f7bc7b954d3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C9E857C50>]}
[0m19:12:56.556900 [error] [Thread-1 (]: 3 of 3 ERROR loading seed file main.reviews .................................... [[31mERROR[0m in 82.02s]
[0m19:12:56.558900 [debug] [Thread-1 (]: Finished running node seed.data_quality.reviews
[0m19:12:56.622094 [debug] [MainThread]: Using duckdb connection "master"
[0m19:12:56.623095 [debug] [MainThread]: On master: BEGIN
[0m19:12:56.623095 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:12:56.635096 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m19:12:56.636768 [debug] [MainThread]: On master: COMMIT
[0m19:12:56.637943 [debug] [MainThread]: Using duckdb connection "master"
[0m19:12:56.638955 [debug] [MainThread]: On master: COMMIT
[0m19:12:56.638955 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m19:12:56.639955 [debug] [MainThread]: On master: Close
[0m19:12:56.643611 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:12:56.643611 [debug] [MainThread]: Connection 'create_data_quality_main' was properly closed.
[0m19:12:56.644631 [debug] [MainThread]: Connection 'list_data_quality_main' was properly closed.
[0m19:12:56.644631 [debug] [MainThread]: Connection 'seed.data_quality.reviews' was properly closed.
[0m19:12:56.646633 [info ] [MainThread]: 
[0m19:12:56.648633 [info ] [MainThread]: Finished running 3 seeds in 0 hours 31 minutes and 0.94 seconds (1860.94s).
[0m19:12:56.653633 [debug] [MainThread]: Command end result
[0m19:12:56.920627 [info ] [MainThread]: 
[0m19:12:56.923621 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m19:12:56.924634 [info ] [MainThread]: 
[0m19:12:56.925639 [error] [MainThread]:   Runtime Error in seed calendar (seeds\calendar.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 297908,2024-06-27,f,$250.00,,2,1125
  Error when converting column "price". Could not convert string "$250.00" to 'DOUBLE'
  
  Column price is being converted as type DOUBLE
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\calendar.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 2 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 3 Set type: DOUBLE Sniffed type: VARCHAR
  Column at position: 4 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 5 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 6 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m19:12:56.936632 [info ] [MainThread]: 
[0m19:12:56.938635 [error] [MainThread]:   Runtime Error in seed listings (seeds\listings.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 17878,https://www.airbnb.com/rooms/17878,20240627045056,2024-06-28,city scrape,"Very Nice 2Br in Copacabana w. balcony, fast WiFi","Please note that elevated rates applies for New Years and Carnival. Price depends on length of stay and number of people. Generally I prefer a stay for 1 week or more and a maximum of 5 people (6 at the most). Contact me, and we will discuss. <br />- Bright and sunny<br />- Large balcony (25 square meters) <br />- High speed WiFi (up to 500MB)<br />- Smart TV (you can watch Netflix etc. if you have an account)<br />- 24h doorman<br />- 1 minute to walk to Copacabana Beach<br />- Silent ""split"" air conditioning<br />- Best spot in Rio","This is the one of the bests spots in Rio. Because of the large balcony and proximity to the beach, it has huge advantages in the current situation.",https://a0.muscache.com/pictures/65320518/30698f38_original.jpg,68997,https://www.airbnb.com/users/show/68997,Matthias,2010-01-08,"Rio de Janeiro, Brazil","I  am a  journalist/writer. Lived  in NYC for 15 years. I  am now based in Rio and published 3 volumes of travel stories on AMAZ0N: ""The World Is My Oyster"". If you have never been to Rio, check out the first story, and you'll get an idea. Apart from Rio, you'll find  29 other travel stories from all around the globe.",within an hour,100%,100%,t,https://a0.muscache.com/im/pictures/user/67b13cea-8c11-49c0-a08d-7f42c330676e.jpg?aki_policy=profile_small,https://a0.muscache.com/im/pictures/user/67b13cea-8c11-49c0-a08d-7f42c330676e.jpg?aki_policy=profile_x_medium,Copacabana,2,5,"['email', 'phone']",t,t,"Rio de Janeiro, Brazil",Copacabana,,-22.96599,-43.1794,Entire condo,Entire home/apt,5,1.0,1 bath,2,2,"[""Smoking allowed"", ""Essentials"", ""Air conditioning"", ""Hangers"", ""Building staff"", ""Kitchen"", ""Refrigerator"", ""Bathtub"", ""Dishes and silverware"", ""Hot water"", ""Microwave"", ""Elevator"", ""Luggage dropoff allowed"", ""Coffee maker"", ""Bed linens"", ""Private entrance"", ""Hair dryer"", ""Iron"", ""Self check-in"", ""Oven"", ""Stove"", ""Patio or balcony"", ""TV with standard cable"", ""Cooking basics"", ""Wifi"", ""Paid parking off premises""]",$310.00,5,28,5,5,28,28,5.0,28.0,,t,6,32,51,274,2024-06-28,319,23,1,2010-07-15,2024-06-08,4.71,4.77,4.64,4.84,4.91,4.77,4.67,,f,1,1,0,0,1.88
  Error when converting column "scrape_id". Could not convert string "20240627045056" to 'INTEGER'
  
  Column scrape_id is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\listings.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 2 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 9 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 18 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 22 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 23 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 25 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 26 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 29 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 34 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 37 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 38 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 40 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 41 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 42 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 43 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 44 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 45 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 46 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 49 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 50 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 51 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 52 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 53 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 54 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 56 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 57 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 58 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 68 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 69 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 70 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 71 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 72 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 73 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m19:12:56.964615 [info ] [MainThread]: 
[0m19:12:56.966614 [error] [MainThread]:   Runtime Error in seed reviews (seeds\reviews.csv)
  Conversion Error: CSV Error on Line: 15
  Original Line: 220377,1122452741612760649,2024-03-28,74325704,Kayque,"Taciana me fez sentir-se na minha pr√≥pria casa. Que sorte eu tive de escolher este Airbnb no Rio de Janeiro! Al√©m da recep√ß√£o muito calorosa da anfitria, foi flex√≠vel com rela√ß√£o ao hor√°rio de chegada e sa√≠da. <br/>O apartamento √© lindo, super limpo e bem decorado, exatamente como mostra no an√∫ncio! Pr√≥ximo a tudo que precisei, bem servido de restaurantes, academias, supermercados, academias, frutaria, etc. O bairro √© bem tranquilo e acolhedor, com arredores bonito! <br/>Super recomendo, atendeu todas as expectativas! <br/>Custo x Benef√≠cio √≥timo. E depois de dias fora de casa, o apto dela nos remeteu um pouco do nosso lar, onde meu filho se sentiu bem relaxado e a vontade. Pessoal recomendo, pois √© um ambiente bem fam√≠lia.<br/>Priscila<br/>janeiro de"
  Error when converting column "id". Could not convert string "1122452741612760649" to 'INTEGER'
  
  Column id is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\reviews.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 1 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 3 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m19:12:56.978615 [info ] [MainThread]: 
[0m19:12:56.980616 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=3 SKIP=0 TOTAL=3
[0m19:12:57.018953 [debug] [MainThread]: Command `dbt seed` failed at 19:12:57.018953 after 1862.60 seconds
[0m19:12:57.019953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C2DAD87A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C9FC1CC50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029C9FAF1970>]}
[0m19:12:57.019953 [debug] [MainThread]: Flushing usage events
[0m19:19:08.347133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A82FDD6270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A82FDD6900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A82FDD6D20>]}


============================== 19:19:08.361711 | 8cc20519-35e0-4d75-841b-b5037a987445 ==============================
[0m19:19:08.361711 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:19:08.362711 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'version_check': 'True', 'debug': 'False', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m19:19:10.407997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8cc20519-35e0-4d75-841b-b5037a987445', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A83001AD80>]}
[0m19:19:10.506991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8cc20519-35e0-4d75-841b-b5037a987445', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A82FFCB260>]}
[0m19:19:10.555990 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m19:19:10.586979 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:19:10.901654 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:19:10.901654 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:19:10.972179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8cc20519-35e0-4d75-841b-b5037a987445', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A82FFCBD40>]}
[0m19:19:11.439038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8cc20519-35e0-4d75-841b-b5037a987445', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A831664B30>]}
[0m19:19:11.440038 [info ] [MainThread]: Found 2 models, 4 data tests, 3 seeds, 421 macros
[0m19:19:11.441041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8cc20519-35e0-4d75-841b-b5037a987445', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8314C2AE0>]}
[0m19:19:11.444039 [info ] [MainThread]: 
[0m19:19:11.445037 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m19:19:11.455257 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_data_quality'
[0m19:19:12.084892 [debug] [ThreadPool]: Using duckdb connection "list_data_quality"
[0m19:19:12.085892 [debug] [ThreadPool]: On list_data_quality: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"data_quality"'
    
  
  
[0m19:19:12.085892 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:19:12.451293 [debug] [ThreadPool]: SQL status: OK in 0.364 seconds
[0m19:19:12.458292 [debug] [ThreadPool]: On list_data_quality: Close
[0m19:19:12.467281 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_quality, now create_data_quality_main)
[0m19:19:12.469288 [debug] [ThreadPool]: Creating schema "database: "data_quality"
schema: "main"
"
[0m19:19:12.487280 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m19:19:12.488282 [debug] [ThreadPool]: On create_data_quality_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_data_quality_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='data_quality'
        and type='sqlite'
    
  
[0m19:19:12.489281 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:19:12.502497 [debug] [ThreadPool]: SQL status: OK in 0.014 seconds
[0m19:19:12.504511 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m19:19:12.505510 [debug] [ThreadPool]: On create_data_quality_main: BEGIN
[0m19:19:12.505510 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m19:19:12.506511 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m19:19:12.506511 [debug] [ThreadPool]: On create_data_quality_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_data_quality_main"} */

    
    
        create schema if not exists "data_quality"."main"
    
[0m19:19:12.508197 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m19:19:12.509210 [debug] [ThreadPool]: On create_data_quality_main: COMMIT
[0m19:19:12.510210 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main"
[0m19:19:12.510210 [debug] [ThreadPool]: On create_data_quality_main: COMMIT
[0m19:19:12.511210 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m19:19:12.512210 [debug] [ThreadPool]: On create_data_quality_main: Close
[0m19:19:12.517210 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_data_quality_main'
[0m19:19:12.525211 [debug] [ThreadPool]: Using duckdb connection "list_data_quality_main"
[0m19:19:12.526211 [debug] [ThreadPool]: On list_data_quality_main: BEGIN
[0m19:19:12.526211 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:19:12.538213 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m19:19:12.538213 [debug] [ThreadPool]: Using duckdb connection "list_data_quality_main"
[0m19:19:12.539212 [debug] [ThreadPool]: On list_data_quality_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality_main"} */
select
      'data_quality' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'data_quality'
  
[0m19:19:12.635056 [debug] [ThreadPool]: SQL status: OK in 0.096 seconds
[0m19:19:12.642892 [debug] [ThreadPool]: On list_data_quality_main: ROLLBACK
[0m19:19:12.698742 [debug] [ThreadPool]: Failed to rollback 'list_data_quality_main'
[0m19:19:12.699740 [debug] [ThreadPool]: On list_data_quality_main: Close
[0m19:19:12.705743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8cc20519-35e0-4d75-841b-b5037a987445', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A830019970>]}
[0m19:19:12.705743 [debug] [MainThread]: Using duckdb connection "master"
[0m19:19:12.706744 [debug] [MainThread]: On master: BEGIN
[0m19:19:12.706744 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:19:12.717743 [debug] [MainThread]: SQL status: OK in 0.011 seconds
[0m19:19:12.718744 [debug] [MainThread]: On master: COMMIT
[0m19:19:12.718744 [debug] [MainThread]: Using duckdb connection "master"
[0m19:19:12.719744 [debug] [MainThread]: On master: COMMIT
[0m19:19:12.719744 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m19:19:12.720744 [debug] [MainThread]: On master: Close
[0m19:19:12.723742 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:19:12.724744 [info ] [MainThread]: 
[0m19:19:12.781487 [debug] [Thread-1 (]: Began running node model.data_quality.my_first_dbt_model
[0m19:19:12.782488 [info ] [Thread-1 (]: 1 of 2 START sql table model main.my_first_dbt_model ........................... [RUN]
[0m19:19:12.784489 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.data_quality.my_first_dbt_model'
[0m19:19:12.785491 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_first_dbt_model
[0m19:19:12.797490 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_first_dbt_model"
[0m19:19:12.799492 [debug] [Thread-1 (]: Began executing node model.data_quality.my_first_dbt_model
[0m19:19:12.848491 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_first_dbt_model"
[0m19:19:12.849492 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m19:19:12.850491 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: BEGIN
[0m19:19:12.850491 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:19:12.861490 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m19:19:12.862492 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m19:19:12.862492 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */

  
    
    

    create  table
      "data_quality"."main"."my_first_dbt_model__dbt_tmp"
  
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
  
[0m19:19:12.870495 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m19:19:12.880487 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m19:19:12.880487 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
alter table "data_quality"."main"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m19:19:12.965801 [debug] [Thread-1 (]: SQL status: OK in 0.085 seconds
[0m19:19:12.973798 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m19:19:12.974803 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
alter table "data_quality"."main"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m19:19:12.975802 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m19:19:13.013800 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m19:19:13.014800 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m19:19:13.015801 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m19:19:13.167340 [debug] [Thread-1 (]: SQL status: OK in 0.152 seconds
[0m19:19:13.175341 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m19:19:13.176344 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
drop table if exists "data_quality"."main"."my_first_dbt_model__dbt_backup" cascade
[0m19:19:13.237599 [debug] [Thread-1 (]: SQL status: OK in 0.061 seconds
[0m19:19:13.240592 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: Close
[0m19:19:13.353400 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cc20519-35e0-4d75-841b-b5037a987445', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A82D93F9E0>]}
[0m19:19:13.354401 [info ] [Thread-1 (]: 1 of 2 OK created sql table model main.my_first_dbt_model ...................... [[32mOK[0m in 0.57s]
[0m19:19:13.357401 [debug] [Thread-1 (]: Finished running node model.data_quality.my_first_dbt_model
[0m19:19:13.359403 [debug] [Thread-1 (]: Began running node model.data_quality.my_second_dbt_model
[0m19:19:13.360401 [info ] [Thread-1 (]: 2 of 2 START sql view model main.my_second_dbt_model ........................... [RUN]
[0m19:19:13.362406 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_quality.my_first_dbt_model, now model.data_quality.my_second_dbt_model)
[0m19:19:13.362406 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_second_dbt_model
[0m19:19:13.368404 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_second_dbt_model"
[0m19:19:13.371402 [debug] [Thread-1 (]: Began executing node model.data_quality.my_second_dbt_model
[0m19:19:13.407406 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_second_dbt_model"
[0m19:19:13.409405 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m19:19:13.410406 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: BEGIN
[0m19:19:13.410406 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:13.422404 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m19:19:13.423402 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m19:19:13.424401 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */

  
  create view "data_quality"."main"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "data_quality"."main"."my_first_dbt_model"
where id = 1
  );

[0m19:19:13.425400 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m19:19:13.429401 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m19:19:13.429401 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
alter view "data_quality"."main"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
[0m19:19:13.431403 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m19:19:13.436400 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m19:19:13.437405 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
alter view "data_quality"."main"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m19:19:13.438400 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m19:19:13.441402 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m19:19:13.442403 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m19:19:13.443403 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m19:19:13.464401 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m19:19:13.469401 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m19:19:13.470403 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
drop view if exists "data_quality"."main"."my_second_dbt_model__dbt_backup" cascade
[0m19:19:13.488411 [debug] [Thread-1 (]: SQL status: OK in 0.018 seconds
[0m19:19:13.490401 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: Close
[0m19:19:13.568803 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cc20519-35e0-4d75-841b-b5037a987445', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8313F42C0>]}
[0m19:19:13.568803 [info ] [Thread-1 (]: 2 of 2 OK created sql view model main.my_second_dbt_model ...................... [[32mOK[0m in 0.21s]
[0m19:19:13.570805 [debug] [Thread-1 (]: Finished running node model.data_quality.my_second_dbt_model
[0m19:19:13.572806 [debug] [MainThread]: Using duckdb connection "master"
[0m19:19:13.573805 [debug] [MainThread]: On master: BEGIN
[0m19:19:13.573805 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:19:13.585806 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m19:19:13.585806 [debug] [MainThread]: On master: COMMIT
[0m19:19:13.586806 [debug] [MainThread]: Using duckdb connection "master"
[0m19:19:13.586806 [debug] [MainThread]: On master: COMMIT
[0m19:19:13.587806 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m19:19:13.587806 [debug] [MainThread]: On master: Close
[0m19:19:13.591806 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:19:13.591806 [debug] [MainThread]: Connection 'create_data_quality_main' was properly closed.
[0m19:19:13.592805 [debug] [MainThread]: Connection 'list_data_quality_main' was properly closed.
[0m19:19:13.592805 [debug] [MainThread]: Connection 'model.data_quality.my_second_dbt_model' was properly closed.
[0m19:19:13.593806 [info ] [MainThread]: 
[0m19:19:13.595015 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 2.15 seconds (2.15s).
[0m19:19:13.596488 [debug] [MainThread]: Command end result
[0m19:19:13.644489 [info ] [MainThread]: 
[0m19:19:13.645488 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:19:13.646488 [info ] [MainThread]: 
[0m19:19:13.647490 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m19:19:13.648933 [debug] [MainThread]: Command `dbt run` succeeded at 19:19:13.648933 after 5.70 seconds
[0m19:19:13.649931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A829E89A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A82FB50B30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A82FD21760>]}
[0m19:19:13.649931 [debug] [MainThread]: Flushing usage events
[0m19:47:21.477588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E21FCCC2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E21FCCC1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E21FCCCFE0>]}


============================== 19:47:21.483586 | a9391998-6707-4df5-ac15-354457a34761 ==============================
[0m19:47:21.483586 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:47:21.484588 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'debug': 'False', 'warn_error': 'None', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt seed', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:47:21.866589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a9391998-6707-4df5-ac15-354457a34761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E21D2ABDA0>]}
[0m19:47:21.943591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a9391998-6707-4df5-ac15-354457a34761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E21FE08800>]}
[0m19:47:21.951586 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m19:47:21.966588 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:47:22.097591 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:47:22.099587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a9391998-6707-4df5-ac15-354457a34761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E2213B7DD0>]}
[0m19:47:23.936893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a9391998-6707-4df5-ac15-354457a34761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E22153EB70>]}
[0m19:47:24.165980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a9391998-6707-4df5-ac15-354457a34761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E219C7F3B0>]}
[0m19:47:24.166979 [info ] [MainThread]: Found 2 models, 3 seeds, 4 data tests, 421 macros
[0m19:47:24.167979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9391998-6707-4df5-ac15-354457a34761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E2217B87D0>]}
[0m19:47:24.169977 [info ] [MainThread]: 
[0m19:47:24.170977 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m19:47:24.177978 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_data_quality'
[0m19:47:24.372910 [debug] [ThreadPool]: Using duckdb connection "list_data_quality"
[0m19:47:24.372910 [debug] [ThreadPool]: On list_data_quality: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"data_quality"'
    
  
  
[0m19:47:24.373914 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:47:24.507329 [debug] [ThreadPool]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"data_quality"'
    
  
  
[0m19:47:24.508341 [debug] [ThreadPool]: DuckDB adapter: Rolling back transaction.
[0m19:47:24.509340 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:47:24.510343 [debug] [MainThread]: Connection 'list_data_quality' was properly closed.
[0m19:47:24.510343 [info ] [MainThread]: 
[0m19:47:24.511339 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.34 seconds (0.34s).
[0m19:47:24.513342 [error] [MainThread]: Encountered an error:
Runtime Error
  IO Error: File is already open in 
  C:\Users\leleb\AppData\Local\Microsoft\WinGet\Packages\DuckDB.cli_Microsoft.Winget.Source_8wekyb3d8bbwe\duckdb.exe (PID 4704)
[0m19:47:24.516341 [debug] [MainThread]: Command `dbt seed` failed at 19:47:24.516341 after 3.34 seconds
[0m19:47:24.517340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E219F687A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E2213DA390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E21FE0A480>]}
[0m19:47:24.517340 [debug] [MainThread]: Flushing usage events
[0m19:48:45.642476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC290871D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC294EF890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC290BE690>]}


============================== 19:48:45.648475 | 5c5b8454-16e4-4642-b895-0ccef171a3f2 ==============================
[0m19:48:45.648475 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:48:45.649475 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'fail_fast': 'False', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt seed', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:48:46.057280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5c5b8454-16e4-4642-b895-0ccef171a3f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC299D83B0>]}
[0m19:48:46.135282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5c5b8454-16e4-4642-b895-0ccef171a3f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC29A34350>]}
[0m19:48:46.143282 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m19:48:46.155281 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:48:46.382281 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:48:46.382281 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:48:46.448281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c5b8454-16e4-4642-b895-0ccef171a3f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC29B75100>]}
[0m19:48:46.594281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c5b8454-16e4-4642-b895-0ccef171a3f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC29ACBB00>]}
[0m19:48:46.595282 [info ] [MainThread]: Found 2 models, 3 seeds, 4 data tests, 421 macros
[0m19:48:46.596281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c5b8454-16e4-4642-b895-0ccef171a3f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC28A213D0>]}
[0m19:48:46.599280 [info ] [MainThread]: 
[0m19:48:46.600027 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m19:48:46.607113 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_data_quality'
[0m19:48:46.792135 [debug] [ThreadPool]: Using duckdb connection "list_data_quality"
[0m19:48:46.793136 [debug] [ThreadPool]: On list_data_quality: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"data_quality"'
    
  
  
[0m19:48:46.794138 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:48:46.815129 [debug] [ThreadPool]: SQL status: OK in 0.021 seconds
[0m19:48:46.817127 [debug] [ThreadPool]: On list_data_quality: Close
[0m19:48:46.821126 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_quality, now create_data_quality_main_public)
[0m19:48:46.822126 [debug] [ThreadPool]: Creating schema "database: "data_quality"
schema: "main_public"
"
[0m19:48:46.831126 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main_public"
[0m19:48:46.832129 [debug] [ThreadPool]: On create_data_quality_main_public: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_data_quality_main_public"} */

    
        select type from duckdb_databases()
        where lower(database_name)='data_quality'
        and type='sqlite'
    
  
[0m19:48:46.832129 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:48:46.844130 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m19:48:46.847130 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main_public"
[0m19:48:46.847130 [debug] [ThreadPool]: On create_data_quality_main_public: BEGIN
[0m19:48:46.848130 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m19:48:46.848130 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main_public"
[0m19:48:46.849130 [debug] [ThreadPool]: On create_data_quality_main_public: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_data_quality_main_public"} */

    
    
        create schema if not exists "data_quality"."main_public"
    
[0m19:48:46.850130 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m19:48:46.851129 [debug] [ThreadPool]: On create_data_quality_main_public: COMMIT
[0m19:48:46.851129 [debug] [ThreadPool]: Using duckdb connection "create_data_quality_main_public"
[0m19:48:46.852130 [debug] [ThreadPool]: On create_data_quality_main_public: COMMIT
[0m19:48:46.880128 [debug] [ThreadPool]: SQL status: OK in 0.028 seconds
[0m19:48:46.881130 [debug] [ThreadPool]: On create_data_quality_main_public: Close
[0m19:48:46.944749 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_data_quality_main'
[0m19:48:46.953751 [debug] [ThreadPool]: Using duckdb connection "list_data_quality_main"
[0m19:48:46.954749 [debug] [ThreadPool]: On list_data_quality_main: BEGIN
[0m19:48:46.955754 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:48:46.978754 [debug] [ThreadPool]: SQL status: OK in 0.023 seconds
[0m19:48:46.979754 [debug] [ThreadPool]: Using duckdb connection "list_data_quality_main"
[0m19:48:46.980754 [debug] [ThreadPool]: On list_data_quality_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality_main"} */
select
      'data_quality' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'data_quality'
  
[0m19:48:47.029748 [debug] [ThreadPool]: SQL status: OK in 0.047 seconds
[0m19:48:47.031750 [debug] [ThreadPool]: On list_data_quality_main: ROLLBACK
[0m19:48:47.034750 [debug] [ThreadPool]: Failed to rollback 'list_data_quality_main'
[0m19:48:47.034750 [debug] [ThreadPool]: On list_data_quality_main: Close
[0m19:48:47.039748 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_quality_main, now list_data_quality_main_public)
[0m19:48:47.044748 [debug] [ThreadPool]: Using duckdb connection "list_data_quality_main_public"
[0m19:48:47.045749 [debug] [ThreadPool]: On list_data_quality_main_public: BEGIN
[0m19:48:47.045749 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:48:47.057746 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m19:48:47.058750 [debug] [ThreadPool]: Using duckdb connection "list_data_quality_main_public"
[0m19:48:47.058750 [debug] [ThreadPool]: On list_data_quality_main_public: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_data_quality_main_public"} */
select
      'data_quality' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_public'
    and lower(table_catalog) = 'data_quality'
  
[0m19:48:47.105750 [debug] [ThreadPool]: SQL status: OK in 0.047 seconds
[0m19:48:47.107749 [debug] [ThreadPool]: On list_data_quality_main_public: ROLLBACK
[0m19:48:47.109750 [debug] [ThreadPool]: Failed to rollback 'list_data_quality_main_public'
[0m19:48:47.109750 [debug] [ThreadPool]: On list_data_quality_main_public: Close
[0m19:48:47.115748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c5b8454-16e4-4642-b895-0ccef171a3f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC2B4BC7A0>]}
[0m19:48:47.115748 [debug] [MainThread]: Using duckdb connection "master"
[0m19:48:47.116750 [debug] [MainThread]: On master: BEGIN
[0m19:48:47.116750 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:48:47.128750 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m19:48:47.129750 [debug] [MainThread]: On master: COMMIT
[0m19:48:47.130749 [debug] [MainThread]: Using duckdb connection "master"
[0m19:48:47.130749 [debug] [MainThread]: On master: COMMIT
[0m19:48:47.131750 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m19:48:47.131750 [debug] [MainThread]: On master: Close
[0m19:48:47.134748 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:48:47.135892 [info ] [MainThread]: 
[0m19:48:47.140910 [debug] [Thread-1 (]: Began running node seed.data_quality.calendar
[0m19:48:47.141904 [info ] [Thread-1 (]: 1 of 3 START seed file main_public.calendar .................................... [RUN]
[0m19:48:47.142906 [debug] [Thread-1 (]: Acquiring new duckdb connection 'seed.data_quality.calendar'
[0m19:48:47.142906 [debug] [Thread-1 (]: Began compiling node seed.data_quality.calendar
[0m19:48:47.143904 [debug] [Thread-1 (]: Began executing node seed.data_quality.calendar
[0m20:10:54.476954 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.calendar"
[0m20:10:54.521612 [debug] [Thread-1 (]: On seed.data_quality.calendar: BEGIN
[0m20:10:54.522632 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:10:56.148150 [debug] [Thread-1 (]: SQL status: OK in 1.625 seconds
[0m20:10:56.150153 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.calendar"
[0m20:10:56.151154 [debug] [Thread-1 (]: On seed.data_quality.calendar: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "seed.data_quality.calendar"} */

    create table "data_quality"."main_public"."calendar" ("listing_id" integer,"date" date,"available" text,"price" float8,"adjusted_price" integer,"minimum_nights" integer,"maximum_nights" integer)
  
[0m20:10:56.165151 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m20:10:56.553889 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.calendar"
[0m20:10:56.553889 [debug] [Thread-1 (]: On seed.data_quality.calendar: 
          COPY "data_quality"."main_public"."calendar" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\calendar.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m20:15:30.530724 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: 
          COPY "data_quality"."main_public"."calendar" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\calendar.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        
[0m20:15:30.531718 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m20:15:30.532717 [debug] [Thread-1 (]: On seed.data_quality.calendar: ROLLBACK
[0m20:15:30.765092 [debug] [Thread-1 (]: Failed to rollback 'seed.data_quality.calendar'
[0m20:15:30.767098 [debug] [Thread-1 (]: On seed.data_quality.calendar: Close
[0m20:15:30.846413 [debug] [Thread-1 (]: Runtime Error in seed calendar (seeds\calendar.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 297908,2024-06-27,f,$250.00,,2,1125
  Error when converting column "price". Could not convert string "$250.00" to 'DOUBLE'
  
  Column price is being converted as type DOUBLE
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\calendar.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 2 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 3 Set type: DOUBLE Sniffed type: VARCHAR
  Column at position: 4 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 5 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 6 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m20:15:30.896186 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c5b8454-16e4-4642-b895-0ccef171a3f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC2B136270>]}
[0m20:15:30.900956 [error] [Thread-1 (]: 1 of 3 ERROR loading seed file main_public.calendar ............................ [[31mERROR[0m in 1603.71s]
[0m20:15:30.911954 [debug] [Thread-1 (]: Finished running node seed.data_quality.calendar
[0m20:15:30.912957 [debug] [Thread-1 (]: Began running node seed.data_quality.listings
[0m20:15:30.916953 [info ] [Thread-1 (]: 2 of 3 START seed file main_public.listings .................................... [RUN]
[0m20:15:30.925795 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.data_quality.calendar, now seed.data_quality.listings)
[0m20:15:30.926796 [debug] [Thread-1 (]: Began compiling node seed.data_quality.listings
[0m20:15:30.927794 [debug] [Thread-1 (]: Began executing node seed.data_quality.listings
[0m20:15:56.590560 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.listings"
[0m20:15:56.591563 [debug] [Thread-1 (]: On seed.data_quality.listings: BEGIN
[0m20:15:56.591563 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:15:56.602563 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m20:15:56.603563 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.listings"
[0m20:15:56.604562 [debug] [Thread-1 (]: On seed.data_quality.listings: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "seed.data_quality.listings"} */

    create table "data_quality"."main_public"."listings" ("id" integer,"listing_url" text,"scrape_id" integer,"last_scraped" date,"source" text,"name" text,"description" text,"neighborhood_overview" text,"picture_url" text,"host_id" integer,"host_url" text,"host_name" text,"host_since" date,"host_location" text,"host_about" text,"host_response_time" text,"host_response_rate" text,"host_acceptance_rate" text,"host_is_superhost" text,"host_thumbnail_url" text,"host_picture_url" text,"host_neighbourhood" text,"host_listings_count" integer,"host_total_listings_count" integer,"host_verifications" text,"host_has_profile_pic" text,"host_identity_verified" text,"neighbourhood" text,"neighbourhood_cleansed" text,"neighbourhood_group_cleansed" integer,"latitude" float8,"longitude" float8,"property_type" text,"room_type" text,"accommodates" integer,"bathrooms" float8,"bathrooms_text" text,"bedrooms" integer,"beds" integer,"amenities" text,"price" integer,"minimum_nights" integer,"maximum_nights" integer,"minimum_minimum_nights" integer,"maximum_minimum_nights" integer,"minimum_maximum_nights" integer,"maximum_maximum_nights" integer,"minimum_nights_avg_ntm" float8,"maximum_nights_avg_ntm" float8,"calendar_updated" integer,"has_availability" text,"availability_30" integer,"availability_60" integer,"availability_90" integer,"availability_365" integer,"calendar_last_scraped" date,"number_of_reviews" integer,"number_of_reviews_ltm" integer,"number_of_reviews_l30d" integer,"first_review" date,"last_review" date,"review_scores_rating" float8,"review_scores_accuracy" float8,"review_scores_cleanliness" float8,"review_scores_checkin" float8,"review_scores_communication" float8,"review_scores_location" float8,"review_scores_value" float8,"license" integer,"instant_bookable" text,"calculated_host_listings_count" integer,"calculated_host_listings_count_entire_homes" integer,"calculated_host_listings_count_private_rooms" integer,"calculated_host_listings_count_shared_rooms" integer,"reviews_per_month" float8)
  
[0m20:15:56.606562 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m20:15:56.607562 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.listings"
[0m20:15:56.608561 [debug] [Thread-1 (]: On seed.data_quality.listings: 
          COPY "data_quality"."main_public"."listings" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\listings.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m20:15:56.927585 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: 
          COPY "data_quality"."main_public"."listings" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\listings.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        
[0m20:15:56.929585 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m20:15:56.930585 [debug] [Thread-1 (]: On seed.data_quality.listings: ROLLBACK
[0m20:15:56.938604 [debug] [Thread-1 (]: Failed to rollback 'seed.data_quality.listings'
[0m20:15:56.938604 [debug] [Thread-1 (]: On seed.data_quality.listings: Close
[0m20:15:56.947604 [debug] [Thread-1 (]: Runtime Error in seed listings (seeds\listings.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 17878,https://www.airbnb.com/rooms/17878,20240627045056,2024-06-28,city scrape,"Very Nice 2Br in Copacabana w. balcony, fast WiFi","Please note that elevated rates applies for New Years and Carnival. Price depends on length of stay and number of people. Generally I prefer a stay for 1 week or more and a maximum of 5 people (6 at the most). Contact me, and we will discuss. <br />- Bright and sunny<br />- Large balcony (25 square meters) <br />- High speed WiFi (up to 500MB)<br />- Smart TV (you can watch Netflix etc. if you have an account)<br />- 24h doorman<br />- 1 minute to walk to Copacabana Beach<br />- Silent ""split"" air conditioning<br />- Best spot in Rio","This is the one of the bests spots in Rio. Because of the large balcony and proximity to the beach, it has huge advantages in the current situation.",https://a0.muscache.com/pictures/65320518/30698f38_original.jpg,68997,https://www.airbnb.com/users/show/68997,Matthias,2010-01-08,"Rio de Janeiro, Brazil","I  am a  journalist/writer. Lived  in NYC for 15 years. I  am now based in Rio and published 3 volumes of travel stories on AMAZ0N: ""The World Is My Oyster"". If you have never been to Rio, check out the first story, and you'll get an idea. Apart from Rio, you'll find  29 other travel stories from all around the globe.",within an hour,100%,100%,t,https://a0.muscache.com/im/pictures/user/67b13cea-8c11-49c0-a08d-7f42c330676e.jpg?aki_policy=profile_small,https://a0.muscache.com/im/pictures/user/67b13cea-8c11-49c0-a08d-7f42c330676e.jpg?aki_policy=profile_x_medium,Copacabana,2,5,"['email', 'phone']",t,t,"Rio de Janeiro, Brazil",Copacabana,,-22.96599,-43.1794,Entire condo,Entire home/apt,5,1.0,1 bath,2,2,"[""Smoking allowed"", ""Essentials"", ""Air conditioning"", ""Hangers"", ""Building staff"", ""Kitchen"", ""Refrigerator"", ""Bathtub"", ""Dishes and silverware"", ""Hot water"", ""Microwave"", ""Elevator"", ""Luggage dropoff allowed"", ""Coffee maker"", ""Bed linens"", ""Private entrance"", ""Hair dryer"", ""Iron"", ""Self check-in"", ""Oven"", ""Stove"", ""Patio or balcony"", ""TV with standard cable"", ""Cooking basics"", ""Wifi"", ""Paid parking off premises""]",$310.00,5,28,5,5,28,28,5.0,28.0,,t,6,32,51,274,2024-06-28,319,23,1,2010-07-15,2024-06-08,4.71,4.77,4.64,4.84,4.91,4.77,4.67,,f,1,1,0,0,1.88
  Error when converting column "scrape_id". Could not convert string "20240627045056" to 'INTEGER'
  
  Column scrape_id is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\listings.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 2 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 9 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 18 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 22 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 23 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 25 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 26 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 29 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 34 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 37 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 38 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 40 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 41 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 42 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 43 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 44 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 45 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 46 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 49 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 50 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 51 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 52 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 53 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 54 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 56 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 57 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 58 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 68 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 69 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 70 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 71 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 72 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 73 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m20:15:56.955614 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c5b8454-16e4-4642-b895-0ccef171a3f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC299EA240>]}
[0m20:15:56.956602 [error] [Thread-1 (]: 2 of 3 ERROR loading seed file main_public.listings ............................ [[31mERROR[0m in 26.03s]
[0m20:15:56.958603 [debug] [Thread-1 (]: Finished running node seed.data_quality.listings
[0m20:15:56.959602 [debug] [Thread-1 (]: Began running node seed.data_quality.reviews
[0m20:15:56.960603 [info ] [Thread-1 (]: 3 of 3 START seed file main_public.reviews ..................................... [RUN]
[0m20:15:56.960603 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly seed.data_quality.listings, now seed.data_quality.reviews)
[0m20:15:56.961603 [debug] [Thread-1 (]: Began compiling node seed.data_quality.reviews
[0m20:15:56.961603 [debug] [Thread-1 (]: Began executing node seed.data_quality.reviews
[0m20:17:08.427582 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.reviews"
[0m20:17:08.428585 [debug] [Thread-1 (]: On seed.data_quality.reviews: BEGIN
[0m20:17:08.429583 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:17:08.441585 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m20:17:08.442583 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.reviews"
[0m20:17:08.442583 [debug] [Thread-1 (]: On seed.data_quality.reviews: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "seed.data_quality.reviews"} */

    create table "data_quality"."main_public"."reviews" ("listing_id" integer,"id" integer,"date" date,"reviewer_id" integer,"reviewer_name" text,"comments" text)
  
[0m20:17:08.443584 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m20:17:08.445581 [debug] [Thread-1 (]: Using duckdb connection "seed.data_quality.reviews"
[0m20:17:08.446582 [debug] [Thread-1 (]: On seed.data_quality.reviews: 
          COPY "data_quality"."main_public"."reviews" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\reviews.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m20:17:08.551600 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: 
          COPY "data_quality"."main_public"."reviews" FROM 'D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\reviews.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        
[0m20:17:08.552600 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m20:17:08.553601 [debug] [Thread-1 (]: On seed.data_quality.reviews: ROLLBACK
[0m20:17:08.561602 [debug] [Thread-1 (]: Failed to rollback 'seed.data_quality.reviews'
[0m20:17:08.561602 [debug] [Thread-1 (]: On seed.data_quality.reviews: Close
[0m20:17:08.568600 [debug] [Thread-1 (]: Runtime Error in seed reviews (seeds\reviews.csv)
  Conversion Error: CSV Error on Line: 15
  Original Line: 220377,1122452741612760649,2024-03-28,74325704,Kayque,"Taciana me fez sentir-se na minha pr√≥pria casa. Que sorte eu tive de escolher este Airbnb no Rio de Janeiro! Al√©m da recep√ß√£o muito calorosa da anfitria, foi flex√≠vel com rela√ß√£o ao hor√°rio de chegada e sa√≠da. <br/>O apartamento √© lindo, super limpo e bem decorado, exatamente como mostra no an√∫ncio! Pr√≥ximo a tudo que precisei, bem servido de restaurantes, academias, supermercados, academias, frutaria, etc. O bairro √© bem tranquilo e acolhedor, com arredores bonito! <br/>Super recomendo, atendeu todas as expectativas! <br/>Custo x Benef√≠cio √≥timo. E depois de dias fora de casa, o apto dela nos remeteu um pouco do nosso lar, onde meu filho se sentiu bem relaxado e a vontade. Pessoal recomendo, pois √© um ambiente bem fam√≠lia.<br/>Priscila<br/>janeiro de"
  Error when converting column "id". Could not convert string "1122452741612760649" to 'INTEGER'
  
  Column id is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\reviews.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 1 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 3 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m20:17:08.569605 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c5b8454-16e4-4642-b895-0ccef171a3f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC29A7A8D0>]}
[0m20:17:08.570600 [error] [Thread-1 (]: 3 of 3 ERROR loading seed file main_public.reviews ............................. [[31mERROR[0m in 71.61s]
[0m20:17:08.572743 [debug] [Thread-1 (]: Finished running node seed.data_quality.reviews
[0m20:17:08.616538 [debug] [MainThread]: Using duckdb connection "master"
[0m20:17:08.616538 [debug] [MainThread]: On master: BEGIN
[0m20:17:08.617538 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:17:08.627536 [debug] [MainThread]: SQL status: OK in 0.011 seconds
[0m20:17:08.628539 [debug] [MainThread]: On master: COMMIT
[0m20:17:08.629539 [debug] [MainThread]: Using duckdb connection "master"
[0m20:17:08.629539 [debug] [MainThread]: On master: COMMIT
[0m20:17:08.630538 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m20:17:08.630538 [debug] [MainThread]: On master: Close
[0m20:17:08.633538 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:17:08.633538 [debug] [MainThread]: Connection 'create_data_quality_main_public' was properly closed.
[0m20:17:08.634539 [debug] [MainThread]: Connection 'list_data_quality_main_public' was properly closed.
[0m20:17:08.634539 [debug] [MainThread]: Connection 'seed.data_quality.reviews' was properly closed.
[0m20:17:08.635538 [info ] [MainThread]: 
[0m20:17:08.639732 [info ] [MainThread]: Finished running 3 seeds in 0 hours 28 minutes and 22.04 seconds (1702.04s).
[0m20:17:08.642755 [debug] [MainThread]: Command end result
[0m20:17:08.821649 [info ] [MainThread]: 
[0m20:17:08.822656 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m20:17:08.824652 [info ] [MainThread]: 
[0m20:17:08.825647 [error] [MainThread]:   Runtime Error in seed calendar (seeds\calendar.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 297908,2024-06-27,f,$250.00,,2,1125
  Error when converting column "price". Could not convert string "$250.00" to 'DOUBLE'
  
  Column price is being converted as type DOUBLE
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\calendar.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 2 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 3 Set type: DOUBLE Sniffed type: VARCHAR
  Column at position: 4 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 5 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 6 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m20:17:08.831649 [info ] [MainThread]: 
[0m20:17:08.832646 [error] [MainThread]:   Runtime Error in seed listings (seeds\listings.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 17878,https://www.airbnb.com/rooms/17878,20240627045056,2024-06-28,city scrape,"Very Nice 2Br in Copacabana w. balcony, fast WiFi","Please note that elevated rates applies for New Years and Carnival. Price depends on length of stay and number of people. Generally I prefer a stay for 1 week or more and a maximum of 5 people (6 at the most). Contact me, and we will discuss. <br />- Bright and sunny<br />- Large balcony (25 square meters) <br />- High speed WiFi (up to 500MB)<br />- Smart TV (you can watch Netflix etc. if you have an account)<br />- 24h doorman<br />- 1 minute to walk to Copacabana Beach<br />- Silent ""split"" air conditioning<br />- Best spot in Rio","This is the one of the bests spots in Rio. Because of the large balcony and proximity to the beach, it has huge advantages in the current situation.",https://a0.muscache.com/pictures/65320518/30698f38_original.jpg,68997,https://www.airbnb.com/users/show/68997,Matthias,2010-01-08,"Rio de Janeiro, Brazil","I  am a  journalist/writer. Lived  in NYC for 15 years. I  am now based in Rio and published 3 volumes of travel stories on AMAZ0N: ""The World Is My Oyster"". If you have never been to Rio, check out the first story, and you'll get an idea. Apart from Rio, you'll find  29 other travel stories from all around the globe.",within an hour,100%,100%,t,https://a0.muscache.com/im/pictures/user/67b13cea-8c11-49c0-a08d-7f42c330676e.jpg?aki_policy=profile_small,https://a0.muscache.com/im/pictures/user/67b13cea-8c11-49c0-a08d-7f42c330676e.jpg?aki_policy=profile_x_medium,Copacabana,2,5,"['email', 'phone']",t,t,"Rio de Janeiro, Brazil",Copacabana,,-22.96599,-43.1794,Entire condo,Entire home/apt,5,1.0,1 bath,2,2,"[""Smoking allowed"", ""Essentials"", ""Air conditioning"", ""Hangers"", ""Building staff"", ""Kitchen"", ""Refrigerator"", ""Bathtub"", ""Dishes and silverware"", ""Hot water"", ""Microwave"", ""Elevator"", ""Luggage dropoff allowed"", ""Coffee maker"", ""Bed linens"", ""Private entrance"", ""Hair dryer"", ""Iron"", ""Self check-in"", ""Oven"", ""Stove"", ""Patio or balcony"", ""TV with standard cable"", ""Cooking basics"", ""Wifi"", ""Paid parking off premises""]",$310.00,5,28,5,5,28,28,5.0,28.0,,t,6,32,51,274,2024-06-28,319,23,1,2010-07-15,2024-06-08,4.71,4.77,4.64,4.84,4.91,4.77,4.67,,f,1,1,0,0,1.88
  Error when converting column "scrape_id". Could not convert string "20240627045056" to 'INTEGER'
  
  Column scrape_id is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\listings.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 2 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 9 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 18 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 22 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 23 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 25 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 26 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 29 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 34 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 37 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 38 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 40 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 41 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 42 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 43 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 44 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 45 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 46 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 49 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 50 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 51 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 52 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 53 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 54 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 56 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 57 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 58 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 68 Set type: INTEGER Sniffed type: VARCHAR
  Column at position: 69 Set type: VARCHAR Sniffed type: BOOLEAN
  Column at position: 70 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 71 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 72 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 73 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m20:17:08.850644 [info ] [MainThread]: 
[0m20:17:08.851646 [error] [MainThread]:   Runtime Error in seed reviews (seeds\reviews.csv)
  Conversion Error: CSV Error on Line: 15
  Original Line: 220377,1122452741612760649,2024-03-28,74325704,Kayque,"Taciana me fez sentir-se na minha pr√≥pria casa. Que sorte eu tive de escolher este Airbnb no Rio de Janeiro! Al√©m da recep√ß√£o muito calorosa da anfitria, foi flex√≠vel com rela√ß√£o ao hor√°rio de chegada e sa√≠da. <br/>O apartamento √© lindo, super limpo e bem decorado, exatamente como mostra no an√∫ncio! Pr√≥ximo a tudo que precisei, bem servido de restaurantes, academias, supermercados, academias, frutaria, etc. O bairro √© bem tranquilo e acolhedor, com arredores bonito! <br/>Super recomendo, atendeu todas as expectativas! <br/>Custo x Benef√≠cio √≥timo. E depois de dias fora de casa, o apto dela nos remeteu um pouco do nosso lar, onde meu filho se sentiu bem relaxado e a vontade. Pessoal recomendo, pois √© um ambiente bem fam√≠lia.<br/>Priscila<br/>janeiro de"
  Error when converting column "id". Could not convert string "1122452741612760649" to 'INTEGER'
  
  Column id is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  
    file = D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\seeds\reviews.csv
    delimiter = , (Set By User)
    quote = " (Auto-Detected)
    escape = " (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = \0 (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 0 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 1 Set type: INTEGER Sniffed type: BIGINT
  Column at position: 3 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m20:17:08.858651 [info ] [MainThread]: 
[0m20:17:08.860644 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=3 SKIP=0 TOTAL=3
[0m20:17:08.888689 [debug] [MainThread]: Command `dbt seed` failed at 20:17:08.888689 after 1703.46 seconds
[0m20:17:08.889704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC29ACA3C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC296B8560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AC2AF82480>]}
[0m20:17:08.889704 [debug] [MainThread]: Flushing usage events
[0m20:44:06.011985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B42F1D5EB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4326AC170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B432679E50>]}


============================== 20:44:06.016985 | 27dd299c-97ff-4132-81a9-9a627337bfc7 ==============================
[0m20:44:06.016985 [info ] [MainThread]: Running with dbt=1.8.7
[0m20:44:06.017901 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m20:44:07.755739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '27dd299c-97ff-4132-81a9-9a627337bfc7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4329D3350>]}
[0m20:44:07.840737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '27dd299c-97ff-4132-81a9-9a627337bfc7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B432AED700>]}
[0m20:44:07.893169 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m20:44:07.927144 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m20:44:08.337636 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m20:44:08.337636 [debug] [MainThread]: Partial parsing: added file: data_quality://models\seed\calendar.sql
[0m20:44:08.697833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '27dd299c-97ff-4132-81a9-9a627337bfc7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B432BF3FB0>]}
[0m20:44:08.963190 [error] [MainThread]: Encountered an error:
Found a cycle: model.data_quality.calendar
[0m20:44:09.009214 [error] [MainThread]: Traceback (most recent call last):
  File "D:\Python\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python\Lib\site-packages\dbt\cli\requires.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python\Lib\site-packages\dbt\cli\requires.py", line 247, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python\Lib\site-packages\dbt\cli\requires.py", line 294, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python\Lib\site-packages\dbt\cli\requires.py", line 332, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python\Lib\site-packages\dbt\cli\main.py", line 569, in run
    results = task.run()
              ^^^^^^^^^^
  File "D:\Python\Lib\site-packages\dbt\task\runnable.py", line 506, in run
    self._runtime_initialize()
  File "D:\Python\Lib\site-packages\dbt\task\compile.py", line 125, in _runtime_initialize
    super()._runtime_initialize()
  File "D:\Python\Lib\site-packages\dbt\task\runnable.py", line 147, in _runtime_initialize
    self.compile_manifest()
  File "D:\Python\Lib\site-packages\dbt\task\base.py", line 145, in compile_manifest
    self.graph = self.compiler.compile(self.manifest)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python\Lib\site-packages\dbt\compilation.py", line 449, in compile
    linker.link_graph(manifest)
  File "D:\Python\Lib\site-packages\dbt\compilation.py", line 192, in link_graph
    raise RuntimeError("Found a cycle: {}".format(cycle))
RuntimeError: Found a cycle: model.data_quality.calendar

[0m20:44:09.017214 [debug] [MainThread]: Command `dbt run` failed at 20:44:09.017214 after 3.37 seconds
[0m20:44:09.018216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4329BB650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B434155DC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4343E3CB0>]}
[0m20:44:09.018216 [debug] [MainThread]: Flushing usage events
[0m20:48:25.884683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001730DE99550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001730E72AFC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001730F75C9E0>]}


============================== 20:48:25.889684 | 60282cad-f329-460a-aa79-89ff44965a7d ==============================
[0m20:48:25.889684 [info ] [MainThread]: Running with dbt=1.8.7
[0m20:48:25.891682 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'fail_fast': 'False', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m20:48:26.285679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '60282cad-f329-460a-aa79-89ff44965a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173121DE870>]}
[0m20:48:26.365680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '60282cad-f329-460a-aa79-89ff44965a7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001730FB54950>]}
[0m20:48:26.373682 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m20:48:26.387680 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m20:48:26.629683 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m20:48:26.630682 [debug] [MainThread]: Partial parsing: updated file: data_quality://models\seed\calendar.sql
[0m20:48:26.874684 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.data_quality.calendar' (models\seed\calendar.sql) depends on a source named 'schema.calendar' which was not found
[0m20:48:26.878771 [debug] [MainThread]: Command `dbt run` failed at 20:48:26.877771 after 1.20 seconds
[0m20:48:26.878771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017311769B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001730FC5C2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017311FC2150>]}
[0m20:48:26.879770 [debug] [MainThread]: Flushing usage events
[0m21:13:38.520672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7B4BBA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D78ADB860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D77BCAB70>]}


============================== 21:13:38.525669 | d215f992-c203-4cdc-b5b6-0f5fe82fb2be ==============================
[0m21:13:38.525669 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:13:38.526670 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:13:38.926668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd215f992-c203-4cdc-b5b6-0f5fe82fb2be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7B6F5730>]}
[0m21:13:39.006669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd215f992-c203-4cdc-b5b6-0f5fe82fb2be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7B6F45C0>]}
[0m21:13:39.013669 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m21:13:39.026670 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:13:39.161673 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m21:13:39.162675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd215f992-c203-4cdc-b5b6-0f5fe82fb2be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7ACC7140>]}
[0m21:13:41.015487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd215f992-c203-4cdc-b5b6-0f5fe82fb2be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7CE00C80>]}
[0m21:13:41.250194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd215f992-c203-4cdc-b5b6-0f5fe82fb2be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7B310BF0>]}
[0m21:13:41.251193 [info ] [MainThread]: Found 2 models, 3 seeds, 4 data tests, 421 macros
[0m21:13:41.252190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd215f992-c203-4cdc-b5b6-0f5fe82fb2be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7916D580>]}
[0m21:13:41.254191 [info ] [MainThread]: 
[0m21:13:41.255193 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m21:13:41.277283 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_bronze'
[0m21:13:41.666419 [debug] [ThreadPool]: Using duckdb connection "list_bronze"
[0m21:13:41.667418 [debug] [ThreadPool]: On list_bronze: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_bronze"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"bronze"'
    
  
  
[0m21:13:41.667418 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:13:41.737431 [debug] [ThreadPool]: SQL status: OK in 0.069 seconds
[0m21:13:41.739432 [debug] [ThreadPool]: On list_bronze: Close
[0m21:13:41.743432 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_bronze, now create_bronze_main)
[0m21:13:41.743432 [debug] [ThreadPool]: Creating schema "database: "bronze"
schema: "main"
"
[0m21:13:41.756436 [debug] [ThreadPool]: Using duckdb connection "create_bronze_main"
[0m21:13:41.757439 [debug] [ThreadPool]: On create_bronze_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_bronze_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='bronze'
        and type='sqlite'
    
  
[0m21:13:41.757439 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:13:41.771017 [debug] [ThreadPool]: SQL status: OK in 0.013 seconds
[0m21:13:41.773017 [debug] [ThreadPool]: Using duckdb connection "create_bronze_main"
[0m21:13:41.773017 [debug] [ThreadPool]: On create_bronze_main: BEGIN
[0m21:13:41.774017 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:13:41.774017 [debug] [ThreadPool]: Using duckdb connection "create_bronze_main"
[0m21:13:41.775018 [debug] [ThreadPool]: On create_bronze_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_bronze_main"} */

    
    
        create schema if not exists "bronze"."main"
    
[0m21:13:41.775018 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:13:41.777018 [debug] [ThreadPool]: On create_bronze_main: COMMIT
[0m21:13:41.777018 [debug] [ThreadPool]: Using duckdb connection "create_bronze_main"
[0m21:13:41.778017 [debug] [ThreadPool]: On create_bronze_main: COMMIT
[0m21:13:41.778017 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:13:41.779018 [debug] [ThreadPool]: On create_bronze_main: Close
[0m21:13:41.783021 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_bronze_main_public'
[0m21:13:41.792021 [debug] [ThreadPool]: Using duckdb connection "list_bronze_main_public"
[0m21:13:41.793018 [debug] [ThreadPool]: On list_bronze_main_public: BEGIN
[0m21:13:41.793018 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:13:41.806022 [debug] [ThreadPool]: SQL status: OK in 0.013 seconds
[0m21:13:41.807019 [debug] [ThreadPool]: Using duckdb connection "list_bronze_main_public"
[0m21:13:41.807019 [debug] [ThreadPool]: On list_bronze_main_public: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_bronze_main_public"} */
select
      'bronze' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_public'
    and lower(table_catalog) = 'bronze'
  
[0m21:13:41.869018 [debug] [ThreadPool]: SQL status: OK in 0.061 seconds
[0m21:13:41.871019 [debug] [ThreadPool]: On list_bronze_main_public: ROLLBACK
[0m21:13:41.916019 [debug] [ThreadPool]: Failed to rollback 'list_bronze_main_public'
[0m21:13:41.917020 [debug] [ThreadPool]: On list_bronze_main_public: Close
[0m21:13:41.921019 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_bronze_main_public, now list_bronze_main)
[0m21:13:41.924270 [debug] [ThreadPool]: Using duckdb connection "list_bronze_main"
[0m21:13:41.924270 [debug] [ThreadPool]: On list_bronze_main: BEGIN
[0m21:13:41.925269 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:13:41.935275 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m21:13:41.936272 [debug] [ThreadPool]: Using duckdb connection "list_bronze_main"
[0m21:13:41.936272 [debug] [ThreadPool]: On list_bronze_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_bronze_main"} */
select
      'bronze' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'bronze'
  
[0m21:13:41.984272 [debug] [ThreadPool]: SQL status: OK in 0.047 seconds
[0m21:13:41.986272 [debug] [ThreadPool]: On list_bronze_main: ROLLBACK
[0m21:13:41.987271 [debug] [ThreadPool]: Failed to rollback 'list_bronze_main'
[0m21:13:41.987271 [debug] [ThreadPool]: On list_bronze_main: Close
[0m21:13:41.992272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd215f992-c203-4cdc-b5b6-0f5fe82fb2be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7CD84320>]}
[0m21:13:41.993270 [debug] [MainThread]: Using duckdb connection "master"
[0m21:13:41.994270 [debug] [MainThread]: On master: BEGIN
[0m21:13:41.994270 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:13:42.007276 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m21:13:42.008272 [debug] [MainThread]: On master: COMMIT
[0m21:13:42.008272 [debug] [MainThread]: Using duckdb connection "master"
[0m21:13:42.009274 [debug] [MainThread]: On master: COMMIT
[0m21:13:42.010273 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m21:13:42.010273 [debug] [MainThread]: On master: Close
[0m21:13:42.013272 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:13:42.014271 [info ] [MainThread]: 
[0m21:13:42.039275 [debug] [Thread-1 (]: Began running node model.data_quality.my_first_dbt_model
[0m21:13:42.040274 [info ] [Thread-1 (]: 1 of 2 START sql table model main.my_first_dbt_model ........................... [RUN]
[0m21:13:42.042273 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.data_quality.my_first_dbt_model'
[0m21:13:42.043276 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_first_dbt_model
[0m21:13:42.059271 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_first_dbt_model"
[0m21:13:42.062270 [debug] [Thread-1 (]: Began executing node model.data_quality.my_first_dbt_model
[0m21:13:42.118274 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_first_dbt_model"
[0m21:13:42.120275 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:13:42.121273 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: BEGIN
[0m21:13:42.122271 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:13:42.131269 [debug] [Thread-1 (]: SQL status: OK in 0.010 seconds
[0m21:13:42.133272 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:13:42.133272 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */

  
    
    

    create  table
      "bronze"."main"."my_first_dbt_model__dbt_tmp"
  
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
  
[0m21:13:42.135270 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m21:13:42.144271 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:13:42.145269 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
alter table "bronze"."main"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:13:42.146270 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m21:13:42.173270 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m21:13:42.173270 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:13:42.174270 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m21:13:42.207080 [debug] [Thread-1 (]: SQL status: OK in 0.032 seconds
[0m21:13:42.214080 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:13:42.215079 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
drop table if exists "bronze"."main"."my_first_dbt_model__dbt_backup" cascade
[0m21:13:42.216080 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m21:13:42.219081 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: Close
[0m21:13:42.291187 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd215f992-c203-4cdc-b5b6-0f5fe82fb2be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D78FCF920>]}
[0m21:13:42.292185 [info ] [Thread-1 (]: 1 of 2 OK created sql table model main.my_first_dbt_model ...................... [[32mOK[0m in 0.25s]
[0m21:13:42.293189 [debug] [Thread-1 (]: Finished running node model.data_quality.my_first_dbt_model
[0m21:13:42.294188 [debug] [Thread-1 (]: Began running node model.data_quality.my_second_dbt_model
[0m21:13:42.295188 [info ] [Thread-1 (]: 2 of 2 START sql view model main.my_second_dbt_model ........................... [RUN]
[0m21:13:42.296187 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_quality.my_first_dbt_model, now model.data_quality.my_second_dbt_model)
[0m21:13:42.297188 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_second_dbt_model
[0m21:13:42.302187 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_second_dbt_model"
[0m21:13:42.304187 [debug] [Thread-1 (]: Began executing node model.data_quality.my_second_dbt_model
[0m21:13:42.332186 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_second_dbt_model"
[0m21:13:42.335188 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:13:42.336191 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: BEGIN
[0m21:13:42.337189 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:13:42.351193 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m21:13:42.352187 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:13:42.353191 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */

  
  create view "bronze"."main"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "bronze"."main"."my_first_dbt_model"
where id = 1
  );

[0m21:13:42.355192 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m21:13:42.361188 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:13:42.362187 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
alter view "bronze"."main"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:13:42.363188 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:13:42.365187 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m21:13:42.366192 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:13:42.367190 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m21:13:42.393185 [debug] [Thread-1 (]: SQL status: OK in 0.026 seconds
[0m21:13:42.397186 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:13:42.397186 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
drop view if exists "bronze"."main"."my_second_dbt_model__dbt_backup" cascade
[0m21:13:42.398185 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:13:42.401190 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: Close
[0m21:13:42.471187 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd215f992-c203-4cdc-b5b6-0f5fe82fb2be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7CC10140>]}
[0m21:13:42.472189 [info ] [Thread-1 (]: 2 of 2 OK created sql view model main.my_second_dbt_model ...................... [[32mOK[0m in 0.17s]
[0m21:13:42.474186 [debug] [Thread-1 (]: Finished running node model.data_quality.my_second_dbt_model
[0m21:13:42.476185 [debug] [MainThread]: Using duckdb connection "master"
[0m21:13:42.476185 [debug] [MainThread]: On master: BEGIN
[0m21:13:42.477187 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:13:42.490186 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m21:13:42.491188 [debug] [MainThread]: On master: COMMIT
[0m21:13:42.491188 [debug] [MainThread]: Using duckdb connection "master"
[0m21:13:42.492189 [debug] [MainThread]: On master: COMMIT
[0m21:13:42.492189 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m21:13:42.493188 [debug] [MainThread]: On master: Close
[0m21:13:42.496186 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:13:42.496186 [debug] [MainThread]: Connection 'create_bronze_main' was properly closed.
[0m21:13:42.496186 [debug] [MainThread]: Connection 'list_bronze_main' was properly closed.
[0m21:13:42.497188 [debug] [MainThread]: Connection 'model.data_quality.my_second_dbt_model' was properly closed.
[0m21:13:42.497188 [info ] [MainThread]: 
[0m21:13:42.498187 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 1.24 seconds (1.24s).
[0m21:13:42.501189 [debug] [MainThread]: Command end result
[0m21:13:42.548187 [info ] [MainThread]: 
[0m21:13:42.550190 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:13:42.552188 [info ] [MainThread]: 
[0m21:13:42.553190 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m21:13:42.555189 [debug] [MainThread]: Command `dbt run` succeeded at 21:13:42.555189 after 4.24 seconds
[0m21:13:42.556195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7B200B30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D7AC66CF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D77BCB3E0>]}
[0m21:13:42.557190 [debug] [MainThread]: Flushing usage events
[0m21:15:30.752857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01C975520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01AB41E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01C944170>]}


============================== 21:15:30.758857 | 9603b5b4-fd4b-4664-8275-fff450f19ad5 ==============================
[0m21:15:30.758857 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:15:30.759858 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --target dev_2', 'send_anonymous_usage_stats': 'True'}
[0m21:15:31.184448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9603b5b4-fd4b-4664-8275-fff450f19ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01EC3C8F0>]}
[0m21:15:31.271427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9603b5b4-fd4b-4664-8275-fff450f19ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01D6F42F0>]}
[0m21:15:31.278471 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m21:15:31.295443 [debug] [MainThread]: checksum: 1bfb0b494c874f1089d335ef789d15432af7153ca74b83107d4306396fa43922, vars: {}, profile: , target: dev_2, version: 1.8.7
[0m21:15:31.446454 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m21:15:31.447455 [debug] [MainThread]: previous checksum: 1bfb0b494c874f1089d335ef789d15432af7153ca74b83107d4306396fa43922, current checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0
[0m21:15:31.448454 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m21:15:31.449456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9603b5b4-fd4b-4664-8275-fff450f19ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01CD57290>]}
[0m21:15:33.417607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9603b5b4-fd4b-4664-8275-fff450f19ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01F083B30>]}
[0m21:15:33.625610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9603b5b4-fd4b-4664-8275-fff450f19ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01CC98B90>]}
[0m21:15:33.626607 [info ] [MainThread]: Found 2 models, 3 seeds, 4 data tests, 421 macros
[0m21:15:33.627609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9603b5b4-fd4b-4664-8275-fff450f19ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01AC5C0B0>]}
[0m21:15:33.629607 [info ] [MainThread]: 
[0m21:15:33.630608 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m21:15:33.637607 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_silver'
[0m21:15:33.792608 [debug] [ThreadPool]: Using duckdb connection "list_silver"
[0m21:15:33.792608 [debug] [ThreadPool]: On list_silver: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "connection_name": "list_silver"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"silver"'
    
  
  
[0m21:15:33.793607 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:15:33.839607 [debug] [ThreadPool]: SQL status: OK in 0.046 seconds
[0m21:15:33.840609 [debug] [ThreadPool]: On list_silver: Close
[0m21:15:33.844607 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_silver, now create_silver_main)
[0m21:15:33.845609 [debug] [ThreadPool]: Creating schema "database: "silver"
schema: "main"
"
[0m21:15:33.854607 [debug] [ThreadPool]: Using duckdb connection "create_silver_main"
[0m21:15:33.855608 [debug] [ThreadPool]: On create_silver_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "connection_name": "create_silver_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='silver'
        and type='sqlite'
    
  
[0m21:15:33.855608 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:15:33.867610 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m21:15:33.869609 [debug] [ThreadPool]: Using duckdb connection "create_silver_main"
[0m21:15:33.869609 [debug] [ThreadPool]: On create_silver_main: BEGIN
[0m21:15:33.870607 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:15:33.870607 [debug] [ThreadPool]: Using duckdb connection "create_silver_main"
[0m21:15:33.871609 [debug] [ThreadPool]: On create_silver_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "connection_name": "create_silver_main"} */

    
    
        create schema if not exists "silver"."main"
    
[0m21:15:33.871609 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:15:33.873608 [debug] [ThreadPool]: On create_silver_main: COMMIT
[0m21:15:33.873608 [debug] [ThreadPool]: Using duckdb connection "create_silver_main"
[0m21:15:33.873608 [debug] [ThreadPool]: On create_silver_main: COMMIT
[0m21:15:33.874607 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:15:33.875607 [debug] [ThreadPool]: On create_silver_main: Close
[0m21:15:33.880609 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_silver_main_public'
[0m21:15:33.887531 [debug] [ThreadPool]: Using duckdb connection "list_silver_main_public"
[0m21:15:33.888531 [debug] [ThreadPool]: On list_silver_main_public: BEGIN
[0m21:15:33.888531 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:15:33.900530 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m21:15:33.900530 [debug] [ThreadPool]: Using duckdb connection "list_silver_main_public"
[0m21:15:33.901531 [debug] [ThreadPool]: On list_silver_main_public: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "connection_name": "list_silver_main_public"} */
select
      'silver' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_public'
    and lower(table_catalog) = 'silver'
  
[0m21:15:33.948530 [debug] [ThreadPool]: SQL status: OK in 0.047 seconds
[0m21:15:33.950531 [debug] [ThreadPool]: On list_silver_main_public: ROLLBACK
[0m21:15:33.951531 [debug] [ThreadPool]: Failed to rollback 'list_silver_main_public'
[0m21:15:33.952531 [debug] [ThreadPool]: On list_silver_main_public: Close
[0m21:15:33.956530 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_silver_main_public, now list_silver_main)
[0m21:15:33.959531 [debug] [ThreadPool]: Using duckdb connection "list_silver_main"
[0m21:15:33.960531 [debug] [ThreadPool]: On list_silver_main: BEGIN
[0m21:15:33.960531 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:15:33.970530 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m21:15:33.971531 [debug] [ThreadPool]: Using duckdb connection "list_silver_main"
[0m21:15:33.971531 [debug] [ThreadPool]: On list_silver_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "connection_name": "list_silver_main"} */
select
      'silver' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'silver'
  
[0m21:15:34.017532 [debug] [ThreadPool]: SQL status: OK in 0.045 seconds
[0m21:15:34.019532 [debug] [ThreadPool]: On list_silver_main: ROLLBACK
[0m21:15:34.022531 [debug] [ThreadPool]: Failed to rollback 'list_silver_main'
[0m21:15:34.023530 [debug] [ThreadPool]: On list_silver_main: Close
[0m21:15:34.028536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9603b5b4-fd4b-4664-8275-fff450f19ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01F1328D0>]}
[0m21:15:34.029531 [debug] [MainThread]: Using duckdb connection "master"
[0m21:15:34.030531 [debug] [MainThread]: On master: BEGIN
[0m21:15:34.030531 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:15:34.041533 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m21:15:34.041533 [debug] [MainThread]: On master: COMMIT
[0m21:15:34.042532 [debug] [MainThread]: Using duckdb connection "master"
[0m21:15:34.042532 [debug] [MainThread]: On master: COMMIT
[0m21:15:34.043531 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m21:15:34.043531 [debug] [MainThread]: On master: Close
[0m21:15:34.046530 [info ] [MainThread]: Concurrency: 1 threads (target='dev_2')
[0m21:15:34.047531 [info ] [MainThread]: 
[0m21:15:34.051532 [debug] [Thread-1 (]: Began running node model.data_quality.my_first_dbt_model
[0m21:15:34.052532 [info ] [Thread-1 (]: 1 of 2 START sql table model main.my_first_dbt_model ........................... [RUN]
[0m21:15:34.053533 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.data_quality.my_first_dbt_model'
[0m21:15:34.054533 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_first_dbt_model
[0m21:15:34.066531 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_first_dbt_model"
[0m21:15:34.068530 [debug] [Thread-1 (]: Began executing node model.data_quality.my_first_dbt_model
[0m21:15:34.116530 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_first_dbt_model"
[0m21:15:34.117532 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:15:34.118533 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: BEGIN
[0m21:15:34.118533 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:15:34.130533 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m21:15:34.130533 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:15:34.131531 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "node_id": "model.data_quality.my_first_dbt_model"} */

  
    
    

    create  table
      "silver"."main"."my_first_dbt_model__dbt_tmp"
  
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
  
[0m21:15:34.133531 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m21:15:34.141531 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:15:34.142531 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "node_id": "model.data_quality.my_first_dbt_model"} */
alter table "silver"."main"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:15:34.143532 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:15:34.167531 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m21:15:34.168531 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:15:34.169531 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m21:15:34.194528 [debug] [Thread-1 (]: SQL status: OK in 0.025 seconds
[0m21:15:34.201521 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:15:34.202521 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "node_id": "model.data_quality.my_first_dbt_model"} */
drop table if exists "silver"."main"."my_first_dbt_model__dbt_backup" cascade
[0m21:15:34.202521 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:15:34.208526 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: Close
[0m21:15:34.283201 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9603b5b4-fd4b-4664-8275-fff450f19ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01B05FB90>]}
[0m21:15:34.285202 [info ] [Thread-1 (]: 1 of 2 OK created sql table model main.my_first_dbt_model ...................... [[32mOK[0m in 0.23s]
[0m21:15:34.289203 [debug] [Thread-1 (]: Finished running node model.data_quality.my_first_dbt_model
[0m21:15:34.291208 [debug] [Thread-1 (]: Began running node model.data_quality.my_second_dbt_model
[0m21:15:34.293207 [info ] [Thread-1 (]: 2 of 2 START sql view model main.my_second_dbt_model ........................... [RUN]
[0m21:15:34.296200 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_quality.my_first_dbt_model, now model.data_quality.my_second_dbt_model)
[0m21:15:34.297204 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_second_dbt_model
[0m21:15:34.306204 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_second_dbt_model"
[0m21:15:34.309203 [debug] [Thread-1 (]: Began executing node model.data_quality.my_second_dbt_model
[0m21:15:34.355716 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_second_dbt_model"
[0m21:15:34.357717 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:15:34.357717 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: BEGIN
[0m21:15:34.358716 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:15:34.369717 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m21:15:34.370718 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:15:34.370718 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "node_id": "model.data_quality.my_second_dbt_model"} */

  
  create view "silver"."main"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "silver"."main"."my_first_dbt_model"
where id = 1
  );

[0m21:15:34.371717 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:15:34.375718 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:15:34.376718 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "node_id": "model.data_quality.my_second_dbt_model"} */
alter view "silver"."main"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:15:34.377718 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:15:34.379718 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m21:15:34.379718 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:15:34.380717 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m21:15:34.401716 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m21:15:34.404716 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:15:34.405716 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_2", "node_id": "model.data_quality.my_second_dbt_model"} */
drop view if exists "silver"."main"."my_second_dbt_model__dbt_backup" cascade
[0m21:15:34.405716 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:15:34.407717 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: Close
[0m21:15:34.489352 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9603b5b4-fd4b-4664-8275-fff450f19ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01F067CE0>]}
[0m21:15:34.490352 [info ] [Thread-1 (]: 2 of 2 OK created sql view model main.my_second_dbt_model ...................... [[32mOK[0m in 0.20s]
[0m21:15:34.492352 [debug] [Thread-1 (]: Finished running node model.data_quality.my_second_dbt_model
[0m21:15:34.494351 [debug] [MainThread]: Using duckdb connection "master"
[0m21:15:34.495351 [debug] [MainThread]: On master: BEGIN
[0m21:15:34.495351 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:15:34.507351 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m21:15:34.508353 [debug] [MainThread]: On master: COMMIT
[0m21:15:34.509352 [debug] [MainThread]: Using duckdb connection "master"
[0m21:15:34.510353 [debug] [MainThread]: On master: COMMIT
[0m21:15:34.511358 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m21:15:34.512359 [debug] [MainThread]: On master: Close
[0m21:15:34.516353 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:15:34.517352 [debug] [MainThread]: Connection 'create_silver_main' was properly closed.
[0m21:15:34.517352 [debug] [MainThread]: Connection 'list_silver_main' was properly closed.
[0m21:15:34.518354 [debug] [MainThread]: Connection 'model.data_quality.my_second_dbt_model' was properly closed.
[0m21:15:34.518354 [info ] [MainThread]: 
[0m21:15:34.520353 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.89 seconds (0.89s).
[0m21:15:34.522352 [debug] [MainThread]: Command end result
[0m21:15:34.575354 [info ] [MainThread]: 
[0m21:15:34.576353 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:15:34.577351 [info ] [MainThread]: 
[0m21:15:34.578351 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m21:15:34.580349 [debug] [MainThread]: Command `dbt run` succeeded at 21:15:34.580349 after 4.10 seconds
[0m21:15:34.580349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01A7CB320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01C610A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B01CDFA870>]}
[0m21:15:34.581350 [debug] [MainThread]: Flushing usage events
[0m21:15:41.889543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A49EF1DF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4BCAE750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4BCAE570>]}


============================== 21:15:41.894544 | 63d1140f-f16f-467e-bd5e-12450828c454 ==============================
[0m21:15:41.894544 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:15:41.895112 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'debug': 'False', 'warn_error': 'None', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --target dev_3', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:15:42.290779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '63d1140f-f16f-467e-bd5e-12450828c454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4CA5AC60>]}
[0m21:15:42.367397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '63d1140f-f16f-467e-bd5e-12450828c454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4900A9F0>]}
[0m21:15:42.375045 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m21:15:42.388044 [debug] [MainThread]: checksum: 09ab186d54acd921e2b5e38b16fb2b89e83848ad59aa79ffb4eca47e48c983f1, vars: {}, profile: , target: dev_3, version: 1.8.7
[0m21:15:42.518916 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m21:15:42.519918 [debug] [MainThread]: previous checksum: 09ab186d54acd921e2b5e38b16fb2b89e83848ad59aa79ffb4eca47e48c983f1, current checksum: 1bfb0b494c874f1089d335ef789d15432af7153ca74b83107d4306396fa43922
[0m21:15:42.519918 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m21:15:42.520917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '63d1140f-f16f-467e-bd5e-12450828c454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4E177E00>]}
[0m21:15:44.415915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '63d1140f-f16f-467e-bd5e-12450828c454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4E54F410>]}
[0m21:15:44.637916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '63d1140f-f16f-467e-bd5e-12450828c454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4C878F80>]}
[0m21:15:44.638915 [info ] [MainThread]: Found 2 models, 3 seeds, 4 data tests, 421 macros
[0m21:15:44.639915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '63d1140f-f16f-467e-bd5e-12450828c454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4B9C2630>]}
[0m21:15:44.641915 [info ] [MainThread]: 
[0m21:15:44.642915 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m21:15:44.652916 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_gold'
[0m21:15:44.809498 [debug] [ThreadPool]: Using duckdb connection "list_gold"
[0m21:15:44.810498 [debug] [ThreadPool]: On list_gold: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "connection_name": "list_gold"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"gold"'
    
  
  
[0m21:15:44.810498 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:15:44.854496 [debug] [ThreadPool]: SQL status: OK in 0.043 seconds
[0m21:15:44.856497 [debug] [ThreadPool]: On list_gold: Close
[0m21:15:44.860499 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_gold, now create_gold_main)
[0m21:15:44.860499 [debug] [ThreadPool]: Creating schema "database: "gold"
schema: "main"
"
[0m21:15:44.870498 [debug] [ThreadPool]: Using duckdb connection "create_gold_main"
[0m21:15:44.870498 [debug] [ThreadPool]: On create_gold_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "connection_name": "create_gold_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='gold'
        and type='sqlite'
    
  
[0m21:15:44.871497 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:15:44.882994 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m21:15:44.883993 [debug] [ThreadPool]: Using duckdb connection "create_gold_main"
[0m21:15:44.884993 [debug] [ThreadPool]: On create_gold_main: BEGIN
[0m21:15:44.886004 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:15:44.886004 [debug] [ThreadPool]: Using duckdb connection "create_gold_main"
[0m21:15:44.886004 [debug] [ThreadPool]: On create_gold_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "connection_name": "create_gold_main"} */

    
    
        create schema if not exists "gold"."main"
    
[0m21:15:44.886993 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:15:44.887993 [debug] [ThreadPool]: On create_gold_main: COMMIT
[0m21:15:44.889000 [debug] [ThreadPool]: Using duckdb connection "create_gold_main"
[0m21:15:44.889000 [debug] [ThreadPool]: On create_gold_main: COMMIT
[0m21:15:44.889994 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:15:44.889994 [debug] [ThreadPool]: On create_gold_main: Close
[0m21:15:44.894874 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_gold_main_public'
[0m21:15:44.902886 [debug] [ThreadPool]: Using duckdb connection "list_gold_main_public"
[0m21:15:44.902886 [debug] [ThreadPool]: On list_gold_main_public: BEGIN
[0m21:15:44.903886 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:15:44.913886 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m21:15:44.913886 [debug] [ThreadPool]: Using duckdb connection "list_gold_main_public"
[0m21:15:44.914887 [debug] [ThreadPool]: On list_gold_main_public: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "connection_name": "list_gold_main_public"} */
select
      'gold' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_public'
    and lower(table_catalog) = 'gold'
  
[0m21:15:44.962887 [debug] [ThreadPool]: SQL status: OK in 0.047 seconds
[0m21:15:44.964888 [debug] [ThreadPool]: On list_gold_main_public: ROLLBACK
[0m21:15:44.965886 [debug] [ThreadPool]: Failed to rollback 'list_gold_main_public'
[0m21:15:44.966886 [debug] [ThreadPool]: On list_gold_main_public: Close
[0m21:15:44.971885 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_gold_main_public, now list_gold_main)
[0m21:15:44.974886 [debug] [ThreadPool]: Using duckdb connection "list_gold_main"
[0m21:15:44.974886 [debug] [ThreadPool]: On list_gold_main: BEGIN
[0m21:15:44.975886 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:15:44.985886 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m21:15:44.986886 [debug] [ThreadPool]: Using duckdb connection "list_gold_main"
[0m21:15:44.986886 [debug] [ThreadPool]: On list_gold_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "connection_name": "list_gold_main"} */
select
      'gold' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'gold'
  
[0m21:15:45.035898 [debug] [ThreadPool]: SQL status: OK in 0.048 seconds
[0m21:15:45.036889 [debug] [ThreadPool]: On list_gold_main: ROLLBACK
[0m21:15:45.038887 [debug] [ThreadPool]: Failed to rollback 'list_gold_main'
[0m21:15:45.038887 [debug] [ThreadPool]: On list_gold_main: Close
[0m21:15:45.043886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '63d1140f-f16f-467e-bd5e-12450828c454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4A4A8830>]}
[0m21:15:45.044886 [debug] [MainThread]: Using duckdb connection "master"
[0m21:15:45.044886 [debug] [MainThread]: On master: BEGIN
[0m21:15:45.045885 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:15:45.055885 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m21:15:45.055885 [debug] [MainThread]: On master: COMMIT
[0m21:15:45.056885 [debug] [MainThread]: Using duckdb connection "master"
[0m21:15:45.056885 [debug] [MainThread]: On master: COMMIT
[0m21:15:45.057884 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m21:15:45.057884 [debug] [MainThread]: On master: Close
[0m21:15:45.060884 [info ] [MainThread]: Concurrency: 1 threads (target='dev_3')
[0m21:15:45.061887 [info ] [MainThread]: 
[0m21:15:45.065885 [debug] [Thread-1 (]: Began running node model.data_quality.my_first_dbt_model
[0m21:15:45.066885 [info ] [Thread-1 (]: 1 of 2 START sql table model main.my_first_dbt_model ........................... [RUN]
[0m21:15:45.067886 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.data_quality.my_first_dbt_model'
[0m21:15:45.067886 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_first_dbt_model
[0m21:15:45.079897 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_first_dbt_model"
[0m21:15:45.081884 [debug] [Thread-1 (]: Began executing node model.data_quality.my_first_dbt_model
[0m21:15:45.141887 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_first_dbt_model"
[0m21:15:45.143887 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:15:45.144887 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: BEGIN
[0m21:15:45.144887 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:15:45.156887 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m21:15:45.156887 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:15:45.157886 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "node_id": "model.data_quality.my_first_dbt_model"} */

  
    
    

    create  table
      "gold"."main"."my_first_dbt_model__dbt_tmp"
  
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
  
[0m21:15:45.158885 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m21:15:45.167887 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:15:45.168885 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "node_id": "model.data_quality.my_first_dbt_model"} */
alter table "gold"."main"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:15:45.169889 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:15:45.194223 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m21:15:45.195223 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:15:45.196215 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m21:15:45.213857 [debug] [Thread-1 (]: SQL status: OK in 0.018 seconds
[0m21:15:45.220851 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:15:45.221850 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "node_id": "model.data_quality.my_first_dbt_model"} */
drop table if exists "gold"."main"."my_first_dbt_model__dbt_backup" cascade
[0m21:15:45.222849 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:15:45.225850 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: Close
[0m21:15:45.288962 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '63d1140f-f16f-467e-bd5e-12450828c454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4E783A40>]}
[0m21:15:45.289962 [info ] [Thread-1 (]: 1 of 2 OK created sql table model main.my_first_dbt_model ...................... [[32mOK[0m in 0.22s]
[0m21:15:45.290971 [debug] [Thread-1 (]: Finished running node model.data_quality.my_first_dbt_model
[0m21:15:45.291962 [debug] [Thread-1 (]: Began running node model.data_quality.my_second_dbt_model
[0m21:15:45.292963 [info ] [Thread-1 (]: 2 of 2 START sql view model main.my_second_dbt_model ........................... [RUN]
[0m21:15:45.293960 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_quality.my_first_dbt_model, now model.data_quality.my_second_dbt_model)
[0m21:15:45.294961 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_second_dbt_model
[0m21:15:45.297961 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_second_dbt_model"
[0m21:15:45.298961 [debug] [Thread-1 (]: Began executing node model.data_quality.my_second_dbt_model
[0m21:15:45.326965 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_second_dbt_model"
[0m21:15:45.328965 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:15:45.328965 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: BEGIN
[0m21:15:45.329965 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:15:45.340963 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m21:15:45.340963 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:15:45.341961 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "node_id": "model.data_quality.my_second_dbt_model"} */

  
  create view "gold"."main"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "gold"."main"."my_first_dbt_model"
where id = 1
  );

[0m21:15:45.342960 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:15:45.346963 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:15:45.346963 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "node_id": "model.data_quality.my_second_dbt_model"} */
alter view "gold"."main"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:15:45.347962 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:15:45.349963 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m21:15:45.350962 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:15:45.350962 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m21:15:45.380003 [debug] [Thread-1 (]: SQL status: OK in 0.028 seconds
[0m21:15:45.382994 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:15:45.383994 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev_3", "node_id": "model.data_quality.my_second_dbt_model"} */
drop view if exists "gold"."main"."my_second_dbt_model__dbt_backup" cascade
[0m21:15:45.384992 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:15:45.386995 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: Close
[0m21:15:45.457418 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '63d1140f-f16f-467e-bd5e-12450828c454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4E8202C0>]}
[0m21:15:45.458416 [info ] [Thread-1 (]: 2 of 2 OK created sql view model main.my_second_dbt_model ...................... [[32mOK[0m in 0.16s]
[0m21:15:45.460417 [debug] [Thread-1 (]: Finished running node model.data_quality.my_second_dbt_model
[0m21:15:45.462418 [debug] [MainThread]: Using duckdb connection "master"
[0m21:15:45.462418 [debug] [MainThread]: On master: BEGIN
[0m21:15:45.462418 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:15:45.472414 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m21:15:45.473416 [debug] [MainThread]: On master: COMMIT
[0m21:15:45.473416 [debug] [MainThread]: Using duckdb connection "master"
[0m21:15:45.473416 [debug] [MainThread]: On master: COMMIT
[0m21:15:45.474415 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m21:15:45.475431 [debug] [MainThread]: On master: Close
[0m21:15:45.478420 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:15:45.478420 [debug] [MainThread]: Connection 'create_gold_main' was properly closed.
[0m21:15:45.479420 [debug] [MainThread]: Connection 'list_gold_main' was properly closed.
[0m21:15:45.479420 [debug] [MainThread]: Connection 'model.data_quality.my_second_dbt_model' was properly closed.
[0m21:15:45.480419 [info ] [MainThread]: 
[0m21:15:45.481422 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.84 seconds (0.84s).
[0m21:15:45.483421 [debug] [MainThread]: Command end result
[0m21:15:45.531315 [info ] [MainThread]: 
[0m21:15:45.533312 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:15:45.534316 [info ] [MainThread]: 
[0m21:15:45.535310 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m21:15:45.537313 [debug] [MainThread]: Command `dbt run` succeeded at 21:15:45.537313 after 3.83 seconds
[0m21:15:45.538316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A49EF1DF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4C9FCBC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018A4E446DE0>]}
[0m21:15:45.539313 [debug] [MainThread]: Flushing usage events
[0m21:16:04.906223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5AF60C80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5B514170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE57F585F0>]}


============================== 21:16:04.913228 | 59f3a2eb-03c3-4d4f-bd91-fdb201073e04 ==============================
[0m21:16:04.913228 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:16:04.914556 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --target dev', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:16:05.295686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '59f3a2eb-03c3-4d4f-bd91-fdb201073e04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5B935FA0>]}
[0m21:16:05.374685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '59f3a2eb-03c3-4d4f-bd91-fdb201073e04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE593308C0>]}
[0m21:16:05.382696 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m21:16:05.395685 [debug] [MainThread]: checksum: b72588a61004764de5b9a5a46159da2d5d1870e817a9a65ee379ab1be9083c25, vars: {}, profile: , target: dev, version: 1.8.7
[0m21:16:05.531682 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m21:16:05.532682 [debug] [MainThread]: previous checksum: b72588a61004764de5b9a5a46159da2d5d1870e817a9a65ee379ab1be9083c25, current checksum: 09ab186d54acd921e2b5e38b16fb2b89e83848ad59aa79ffb4eca47e48c983f1
[0m21:16:05.533686 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m21:16:05.534686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '59f3a2eb-03c3-4d4f-bd91-fdb201073e04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5CFB7860>]}
[0m21:16:07.414800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59f3a2eb-03c3-4d4f-bd91-fdb201073e04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5D295520>]}
[0m21:16:07.610801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59f3a2eb-03c3-4d4f-bd91-fdb201073e04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5D34C110>]}
[0m21:16:07.611803 [info ] [MainThread]: Found 2 models, 3 seeds, 4 data tests, 421 macros
[0m21:16:07.612799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '59f3a2eb-03c3-4d4f-bd91-fdb201073e04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5D38F8C0>]}
[0m21:16:07.614800 [info ] [MainThread]: 
[0m21:16:07.615801 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m21:16:07.622802 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_bronze'
[0m21:16:07.776800 [debug] [ThreadPool]: Using duckdb connection "list_bronze"
[0m21:16:07.777756 [debug] [ThreadPool]: On list_bronze: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_bronze"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"bronze"'
    
  
  
[0m21:16:07.777756 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:16:07.792730 [debug] [ThreadPool]: SQL status: OK in 0.014 seconds
[0m21:16:07.795728 [debug] [ThreadPool]: On list_bronze: Close
[0m21:16:07.799729 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_bronze, now create_bronze_main)
[0m21:16:07.799729 [debug] [ThreadPool]: Creating schema "database: "bronze"
schema: "main"
"
[0m21:16:07.809726 [debug] [ThreadPool]: Using duckdb connection "create_bronze_main"
[0m21:16:07.809726 [debug] [ThreadPool]: On create_bronze_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_bronze_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='bronze'
        and type='sqlite'
    
  
[0m21:16:07.810727 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:16:07.821724 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m21:16:07.823726 [debug] [ThreadPool]: Using duckdb connection "create_bronze_main"
[0m21:16:07.823726 [debug] [ThreadPool]: On create_bronze_main: BEGIN
[0m21:16:07.824726 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:16:07.824726 [debug] [ThreadPool]: Using duckdb connection "create_bronze_main"
[0m21:16:07.825727 [debug] [ThreadPool]: On create_bronze_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "create_bronze_main"} */

    
    
        create schema if not exists "bronze"."main"
    
[0m21:16:07.826726 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:16:07.827731 [debug] [ThreadPool]: On create_bronze_main: COMMIT
[0m21:16:07.827731 [debug] [ThreadPool]: Using duckdb connection "create_bronze_main"
[0m21:16:07.828727 [debug] [ThreadPool]: On create_bronze_main: COMMIT
[0m21:16:07.829729 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m21:16:07.829729 [debug] [ThreadPool]: On create_bronze_main: Close
[0m21:16:07.834730 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_bronze_main_public'
[0m21:16:07.841726 [debug] [ThreadPool]: Using duckdb connection "list_bronze_main_public"
[0m21:16:07.842726 [debug] [ThreadPool]: On list_bronze_main_public: BEGIN
[0m21:16:07.842726 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:16:07.854728 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m21:16:07.855730 [debug] [ThreadPool]: Using duckdb connection "list_bronze_main_public"
[0m21:16:07.855730 [debug] [ThreadPool]: On list_bronze_main_public: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_bronze_main_public"} */
select
      'bronze' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_public'
    and lower(table_catalog) = 'bronze'
  
[0m21:16:07.905745 [debug] [ThreadPool]: SQL status: OK in 0.049 seconds
[0m21:16:07.907745 [debug] [ThreadPool]: On list_bronze_main_public: ROLLBACK
[0m21:16:07.909745 [debug] [ThreadPool]: Failed to rollback 'list_bronze_main_public'
[0m21:16:07.909745 [debug] [ThreadPool]: On list_bronze_main_public: Close
[0m21:16:07.914744 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_bronze_main_public, now list_bronze_main)
[0m21:16:07.917744 [debug] [ThreadPool]: Using duckdb connection "list_bronze_main"
[0m21:16:07.917744 [debug] [ThreadPool]: On list_bronze_main: BEGIN
[0m21:16:07.917744 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:16:07.929747 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m21:16:07.929747 [debug] [ThreadPool]: Using duckdb connection "list_bronze_main"
[0m21:16:07.930746 [debug] [ThreadPool]: On list_bronze_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "connection_name": "list_bronze_main"} */
select
      'bronze' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'bronze'
  
[0m21:16:07.978482 [debug] [ThreadPool]: SQL status: OK in 0.047 seconds
[0m21:16:07.980481 [debug] [ThreadPool]: On list_bronze_main: ROLLBACK
[0m21:16:07.982477 [debug] [ThreadPool]: Failed to rollback 'list_bronze_main'
[0m21:16:07.982477 [debug] [ThreadPool]: On list_bronze_main: Close
[0m21:16:07.988478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '59f3a2eb-03c3-4d4f-bd91-fdb201073e04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5B6E3080>]}
[0m21:16:07.989479 [debug] [MainThread]: Using duckdb connection "master"
[0m21:16:07.989479 [debug] [MainThread]: On master: BEGIN
[0m21:16:07.990478 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:16:08.001478 [debug] [MainThread]: SQL status: OK in 0.011 seconds
[0m21:16:08.001478 [debug] [MainThread]: On master: COMMIT
[0m21:16:08.002478 [debug] [MainThread]: Using duckdb connection "master"
[0m21:16:08.002478 [debug] [MainThread]: On master: COMMIT
[0m21:16:08.003479 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m21:16:08.003479 [debug] [MainThread]: On master: Close
[0m21:16:08.007493 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:16:08.008485 [info ] [MainThread]: 
[0m21:16:08.013481 [debug] [Thread-1 (]: Began running node model.data_quality.my_first_dbt_model
[0m21:16:08.014483 [info ] [Thread-1 (]: 1 of 2 START sql table model main.my_first_dbt_model ........................... [RUN]
[0m21:16:08.015484 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.data_quality.my_first_dbt_model'
[0m21:16:08.016481 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_first_dbt_model
[0m21:16:08.030480 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_first_dbt_model"
[0m21:16:08.032483 [debug] [Thread-1 (]: Began executing node model.data_quality.my_first_dbt_model
[0m21:16:08.086478 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_first_dbt_model"
[0m21:16:08.088480 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:16:08.088480 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: BEGIN
[0m21:16:08.089479 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:16:08.100478 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m21:16:08.101478 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:16:08.102476 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */

  
    
    

    create  table
      "bronze"."main"."my_first_dbt_model__dbt_tmp"
  
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
  
[0m21:16:08.103476 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m21:16:08.113482 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:16:08.114481 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
alter table "bronze"."main"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:16:08.115480 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:16:08.119480 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:16:08.120481 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
alter table "bronze"."main"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:16:08.120481 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:16:08.151478 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m21:16:08.152478 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:16:08.153478 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: COMMIT
[0m21:16:08.179519 [debug] [Thread-1 (]: SQL status: OK in 0.026 seconds
[0m21:16:08.186518 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_first_dbt_model"
[0m21:16:08.187518 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_first_dbt_model"} */
drop table if exists "bronze"."main"."my_first_dbt_model__dbt_backup" cascade
[0m21:16:08.203617 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m21:16:08.206610 [debug] [Thread-1 (]: On model.data_quality.my_first_dbt_model: Close
[0m21:16:08.279592 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59f3a2eb-03c3-4d4f-bd91-fdb201073e04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5929FCE0>]}
[0m21:16:08.280594 [info ] [Thread-1 (]: 1 of 2 OK created sql table model main.my_first_dbt_model ...................... [[32mOK[0m in 0.26s]
[0m21:16:08.282594 [debug] [Thread-1 (]: Finished running node model.data_quality.my_first_dbt_model
[0m21:16:08.283593 [debug] [Thread-1 (]: Began running node model.data_quality.my_second_dbt_model
[0m21:16:08.284594 [info ] [Thread-1 (]: 2 of 2 START sql view model main.my_second_dbt_model ........................... [RUN]
[0m21:16:08.285594 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_quality.my_first_dbt_model, now model.data_quality.my_second_dbt_model)
[0m21:16:08.286591 [debug] [Thread-1 (]: Began compiling node model.data_quality.my_second_dbt_model
[0m21:16:08.290590 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_quality.my_second_dbt_model"
[0m21:16:08.291590 [debug] [Thread-1 (]: Began executing node model.data_quality.my_second_dbt_model
[0m21:16:08.320590 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_quality.my_second_dbt_model"
[0m21:16:08.322590 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:16:08.322590 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: BEGIN
[0m21:16:08.323589 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:16:08.338593 [debug] [Thread-1 (]: SQL status: OK in 0.015 seconds
[0m21:16:08.338593 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:16:08.339599 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */

  
  create view "bronze"."main"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "bronze"."main"."my_first_dbt_model"
where id = 1
  );

[0m21:16:08.340590 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:16:08.345591 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:16:08.347594 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
alter view "bronze"."main"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
[0m21:16:08.348592 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:16:08.352590 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:16:08.352590 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
alter view "bronze"."main"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:16:08.353590 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m21:16:08.355593 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m21:16:08.355593 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:16:08.356591 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: COMMIT
[0m21:16:08.380590 [debug] [Thread-1 (]: SQL status: OK in 0.023 seconds
[0m21:16:08.385591 [debug] [Thread-1 (]: Using duckdb connection "model.data_quality.my_second_dbt_model"
[0m21:16:08.386590 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "data_quality", "target_name": "dev", "node_id": "model.data_quality.my_second_dbt_model"} */
drop view if exists "bronze"."main"."my_second_dbt_model__dbt_backup" cascade
[0m21:16:08.404590 [debug] [Thread-1 (]: SQL status: OK in 0.018 seconds
[0m21:16:08.406590 [debug] [Thread-1 (]: On model.data_quality.my_second_dbt_model: Close
[0m21:16:08.478620 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59f3a2eb-03c3-4d4f-bd91-fdb201073e04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5D01AB70>]}
[0m21:16:08.479622 [info ] [Thread-1 (]: 2 of 2 OK created sql view model main.my_second_dbt_model ...................... [[32mOK[0m in 0.19s]
[0m21:16:08.480620 [debug] [Thread-1 (]: Finished running node model.data_quality.my_second_dbt_model
[0m21:16:08.482620 [debug] [MainThread]: Using duckdb connection "master"
[0m21:16:08.483620 [debug] [MainThread]: On master: BEGIN
[0m21:16:08.483620 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:16:08.496623 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m21:16:08.496623 [debug] [MainThread]: On master: COMMIT
[0m21:16:08.497621 [debug] [MainThread]: Using duckdb connection "master"
[0m21:16:08.497621 [debug] [MainThread]: On master: COMMIT
[0m21:16:08.498619 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m21:16:08.498619 [debug] [MainThread]: On master: Close
[0m21:16:08.501621 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:16:08.502620 [debug] [MainThread]: Connection 'create_bronze_main' was properly closed.
[0m21:16:08.502620 [debug] [MainThread]: Connection 'list_bronze_main' was properly closed.
[0m21:16:08.503620 [debug] [MainThread]: Connection 'model.data_quality.my_second_dbt_model' was properly closed.
[0m21:16:08.503620 [info ] [MainThread]: 
[0m21:16:08.504785 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.89 seconds (0.89s).
[0m21:16:08.506801 [debug] [MainThread]: Command end result
[0m21:16:08.548799 [info ] [MainThread]: 
[0m21:16:08.549801 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:16:08.550802 [info ] [MainThread]: 
[0m21:16:08.551801 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m21:16:08.554798 [debug] [MainThread]: Command `dbt run` succeeded at 21:16:08.554798 after 3.84 seconds
[0m21:16:08.555799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5A8AD730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE5B88D310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DE57F585F0>]}
[0m21:16:08.555799 [debug] [MainThread]: Flushing usage events
[0m21:16:27.623598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD84B91F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD86B82870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD86B83140>]}


============================== 21:16:27.629672 | 894bf86c-52ca-44e7-8afd-b7729f1298c5 ==============================
[0m21:16:27.629672 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:16:27.631310 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m21:16:27.680321 [info ] [MainThread]: dbt version: 1.8.7
[0m21:16:27.681321 [info ] [MainThread]: python version: 3.12.6
[0m21:16:27.682318 [info ] [MainThread]: python path: D:\Python\python.exe
[0m21:16:27.683316 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m21:16:27.860514 [info ] [MainThread]: Using profiles dir at D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality
[0m21:16:27.861515 [info ] [MainThread]: Using profiles.yml file at D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\profiles.yml
[0m21:16:27.862516 [info ] [MainThread]: Using dbt_project.yml file at D:\GitHub\Aulas_ADA\Engenharia de Dados - Avan√ßado\#5 - Analytics Engineering\projeto\projeto_modulo_5\data_quality\dbt_project.yml
[0m21:16:27.870514 [info ] [MainThread]: adapter type: duckdb
[0m21:16:27.871515 [info ] [MainThread]: adapter version: 1.9.0
[0m21:16:27.991518 [info ] [MainThread]: Configuration:
[0m21:16:27.992519 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m21:16:27.993519 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m21:16:27.994519 [info ] [MainThread]: Required dependencies:
[0m21:16:27.995515 [debug] [MainThread]: Executing "git --help"
[0m21:16:28.174741 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m21:16:28.176742 [debug] [MainThread]: STDERR: "b''"
[0m21:16:28.176742 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m21:16:28.178744 [info ] [MainThread]: Connection:
[0m21:16:28.179746 [info ] [MainThread]:   database: bronze
[0m21:16:28.179746 [info ] [MainThread]:   schema: main
[0m21:16:28.180744 [info ] [MainThread]:   path: bronze.duckdb
[0m21:16:28.181743 [info ] [MainThread]:   config_options: None
[0m21:16:28.181743 [info ] [MainThread]:   extensions: []
[0m21:16:28.182743 [info ] [MainThread]:   settings: {}
[0m21:16:28.183741 [info ] [MainThread]:   external_root: .
[0m21:16:28.184743 [info ] [MainThread]:   use_credential_provider: None
[0m21:16:28.184743 [info ] [MainThread]:   attach: None
[0m21:16:28.185743 [info ] [MainThread]:   filesystems: None
[0m21:16:28.186744 [info ] [MainThread]:   remote: None
[0m21:16:28.186744 [info ] [MainThread]:   plugins: None
[0m21:16:28.187743 [info ] [MainThread]:   disable_transactions: False
[0m21:16:28.189742 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m21:16:28.190743 [debug] [MainThread]: Acquiring new duckdb connection 'debug'
[0m21:16:28.322742 [debug] [MainThread]: Using duckdb connection "debug"
[0m21:16:28.323742 [debug] [MainThread]: On debug: select 1 as id
[0m21:16:28.323742 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:16:28.337740 [debug] [MainThread]: SQL status: OK in 0.014 seconds
[0m21:16:28.339741 [debug] [MainThread]: On debug: Close
[0m21:16:28.341746 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m21:16:28.343749 [info ] [MainThread]: [32mAll checks passed![0m
[0m21:16:28.345743 [debug] [MainThread]: Command `dbt debug` succeeded at 21:16:28.345743 after 0.92 seconds
[0m21:16:28.345743 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m21:16:28.346743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD872C1370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD875A3350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD88C3E900>]}
[0m21:16:28.346743 [debug] [MainThread]: Flushing usage events
[0m23:08:44.953673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E071DDFBC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E073FD3620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E073FD3EC0>]}


============================== 23:08:44.984941 | 7ff12c3c-3b9b-4ab9-9cd8-b5f6e5c21f9c ==============================
[0m23:08:44.984941 [info ] [MainThread]: Running with dbt=1.8.7
[0m23:08:44.984941 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality\\logs', 'version_check': 'True', 'profiles_dir': 'D:\\GitHub\\Aulas_ADA\\Engenharia de Dados - Avan√ßado\\#5 - Analytics Engineering\\projeto\\projeto_modulo_5\\data_quality', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --target dev_3', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:08:46.081092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7ff12c3c-3b9b-4ab9-9cd8-b5f6e5c21f9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E0749B0170>]}
[0m23:08:46.160413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7ff12c3c-3b9b-4ab9-9cd8-b5f6e5c21f9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E073B3A720>]}
[0m23:08:46.173180 [info ] [MainThread]: Registered adapter: duckdb=1.9.0
[0m23:08:46.185543 [debug] [MainThread]: checksum: 09ab186d54acd921e2b5e38b16fb2b89e83848ad59aa79ffb4eca47e48c983f1, vars: {}, profile: , target: dev_3, version: 1.8.7
[0m23:08:46.356485 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m23:08:46.357484 [debug] [MainThread]: previous checksum: 09ab186d54acd921e2b5e38b16fb2b89e83848ad59aa79ffb4eca47e48c983f1, current checksum: b72588a61004764de5b9a5a46159da2d5d1870e817a9a65ee379ab1be9083c25
[0m23:08:46.357484 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m23:08:46.358437 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m23:08:46.359104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7ff12c3c-3b9b-4ab9-9cd8-b5f6e5c21f9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E074038E00>]}
[0m23:08:47.733227 [error] [MainThread]: Encountered an error:
Parsing Error in model bronze_calendar (models\bronze\bronze_calendar.py)
  dbt allows exactly one model defined per python file, found 0
[0m23:08:47.735228 [debug] [MainThread]: Command `dbt run` failed at 23:08:47.735228 after 3.03 seconds
[0m23:08:47.736226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E071DDFBC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E07605A030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E075F1C6B0>]}
[0m23:08:47.736226 [debug] [MainThread]: Flushing usage events
